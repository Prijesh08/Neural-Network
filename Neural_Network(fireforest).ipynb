{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oct</td>\n",
       "      <td>tue</td>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oct</td>\n",
       "      <td>sat</td>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mar</td>\n",
       "      <td>sun</td>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>32</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>71</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.2</td>\n",
       "      <td>70</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>aug</td>\n",
       "      <td>sat</td>\n",
       "      <td>94.4</td>\n",
       "      <td>146.0</td>\n",
       "      <td>614.7</td>\n",
       "      <td>11.3</td>\n",
       "      <td>25.6</td>\n",
       "      <td>42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>nov</td>\n",
       "      <td>tue</td>\n",
       "      <td>79.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>106.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>11.8</td>\n",
       "      <td>31</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    month  day  FFMC    DMC     DC   ISI  temp  RH  wind  rain  ...  monthfeb  \\\n",
       "0     mar  fri  86.2   26.2   94.3   5.1   8.2  51   6.7   0.0  ...         0   \n",
       "1     oct  tue  90.6   35.4  669.1   6.7  18.0  33   0.9   0.0  ...         0   \n",
       "2     oct  sat  90.6   43.7  686.9   6.7  14.6  33   1.3   0.0  ...         0   \n",
       "3     mar  fri  91.7   33.3   77.5   9.0   8.3  97   4.0   0.2  ...         0   \n",
       "4     mar  sun  89.3   51.3  102.2   9.6  11.4  99   1.8   0.0  ...         0   \n",
       "..    ...  ...   ...    ...    ...   ...   ...  ..   ...   ...  ...       ...   \n",
       "512   aug  sun  81.6   56.7  665.6   1.9  27.8  32   2.7   0.0  ...         0   \n",
       "513   aug  sun  81.6   56.7  665.6   1.9  21.9  71   5.8   0.0  ...         0   \n",
       "514   aug  sun  81.6   56.7  665.6   1.9  21.2  70   6.7   0.0  ...         0   \n",
       "515   aug  sat  94.4  146.0  614.7  11.3  25.6  42   4.0   0.0  ...         0   \n",
       "516   nov  tue  79.5    3.0  106.7   1.1  11.8  31   4.5   0.0  ...         0   \n",
       "\n",
       "     monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  monthoct  \\\n",
       "0           0         0         0         1         0         0         0   \n",
       "1           0         0         0         0         0         0         1   \n",
       "2           0         0         0         0         0         0         1   \n",
       "3           0         0         0         1         0         0         0   \n",
       "4           0         0         0         1         0         0         0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512         0         0         0         0         0         0         0   \n",
       "513         0         0         0         0         0         0         0   \n",
       "514         0         0         0         0         0         0         0   \n",
       "515         0         0         0         0         0         0         0   \n",
       "516         0         0         0         0         0         1         0   \n",
       "\n",
       "     monthsep  size_category  \n",
       "0           0          small  \n",
       "1           0          small  \n",
       "2           0          small  \n",
       "3           0          small  \n",
       "4           0          small  \n",
       "..        ...            ...  \n",
       "512         0          large  \n",
       "513         0          large  \n",
       "514         0          large  \n",
       "515         0          small  \n",
       "516         0          small  \n",
       "\n",
       "[517 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('forestfires.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 517 entries, 0 to 516\n",
      "Data columns (total 31 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   month          517 non-null    object \n",
      " 1   day            517 non-null    object \n",
      " 2   FFMC           517 non-null    float64\n",
      " 3   DMC            517 non-null    float64\n",
      " 4   DC             517 non-null    float64\n",
      " 5   ISI            517 non-null    float64\n",
      " 6   temp           517 non-null    float64\n",
      " 7   RH             517 non-null    int64  \n",
      " 8   wind           517 non-null    float64\n",
      " 9   rain           517 non-null    float64\n",
      " 10  area           517 non-null    float64\n",
      " 11  dayfri         517 non-null    int64  \n",
      " 12  daymon         517 non-null    int64  \n",
      " 13  daysat         517 non-null    int64  \n",
      " 14  daysun         517 non-null    int64  \n",
      " 15  daythu         517 non-null    int64  \n",
      " 16  daytue         517 non-null    int64  \n",
      " 17  daywed         517 non-null    int64  \n",
      " 18  monthapr       517 non-null    int64  \n",
      " 19  monthaug       517 non-null    int64  \n",
      " 20  monthdec       517 non-null    int64  \n",
      " 21  monthfeb       517 non-null    int64  \n",
      " 22  monthjan       517 non-null    int64  \n",
      " 23  monthjul       517 non-null    int64  \n",
      " 24  monthjun       517 non-null    int64  \n",
      " 25  monthmar       517 non-null    int64  \n",
      " 26  monthmay       517 non-null    int64  \n",
      " 27  monthnov       517 non-null    int64  \n",
      " 28  monthoct       517 non-null    int64  \n",
      " 29  monthsep       517 non-null    int64  \n",
      " 30  size_category  517 non-null    object \n",
      "dtypes: float64(8), int64(20), object(3)\n",
      "memory usage: 125.3+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aug    184\n",
       "sep    172\n",
       "mar     54\n",
       "jul     32\n",
       "feb     20\n",
       "jun     17\n",
       "oct     15\n",
       "apr      9\n",
       "dec      9\n",
       "jan      2\n",
       "may      2\n",
       "nov      1\n",
       "Name: month, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['month'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "small    378\n",
       "large    139\n",
       "Name: size_category, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['size_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(['month','day'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    509\n",
       "0.8      2\n",
       "0.2      2\n",
       "0.4      1\n",
       "6.4      1\n",
       "1.4      1\n",
       "1.0      1\n",
       "Name: rain, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['rain'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['FFMC', 'DMC', 'DC', 'ISI', 'temp', 'RH', 'wind', 'rain', 'area',\n",
       "       'dayfri', 'daymon', 'daysat', 'daysun', 'daythu', 'daytue', 'daywed',\n",
       "       'monthapr', 'monthaug', 'monthdec', 'monthfeb', 'monthjan', 'monthjul',\n",
       "       'monthjun', 'monthmar', 'monthmay', 'monthnov', 'monthoct', 'monthsep',\n",
       "       'size_category'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FFMC\n",
      "91.6    28\n",
      "92.1    28\n",
      "91.0    22\n",
      "91.7    19\n",
      "93.7    16\n",
      "        ..\n",
      "50.4     1\n",
      "82.1     1\n",
      "86.3     1\n",
      "85.1     1\n",
      "87.1     1\n",
      "Name: FFMC, Length: 106, dtype: int64 \n",
      "\n",
      "DMC\n",
      "99.0     10\n",
      "129.5     9\n",
      "142.4     8\n",
      "231.1     8\n",
      "137.0     7\n",
      "         ..\n",
      "4.6       1\n",
      "24.9      1\n",
      "133.6     1\n",
      "96.3      1\n",
      "3.2       1\n",
      "Name: DMC, Length: 215, dtype: int64 \n",
      "\n",
      "DC\n",
      "745.3    10\n",
      "692.6     9\n",
      "698.6     8\n",
      "601.4     8\n",
      "692.3     8\n",
      "         ..\n",
      "730.6     1\n",
      "431.6     1\n",
      "74.3      1\n",
      "313.4     1\n",
      "537.4     1\n",
      "Name: DC, Length: 219, dtype: int64 \n",
      "\n",
      "ISI\n",
      "9.6     23\n",
      "7.1     21\n",
      "6.3     20\n",
      "7.0     17\n",
      "8.4     17\n",
      "        ..\n",
      "7.3      1\n",
      "12.1     1\n",
      "14.6     1\n",
      "56.1     1\n",
      "22.7     1\n",
      "Name: ISI, Length: 119, dtype: int64 \n",
      "\n",
      "temp\n",
      "17.4    8\n",
      "19.6    8\n",
      "15.4    7\n",
      "20.6    7\n",
      "23.4    6\n",
      "       ..\n",
      "29.6    1\n",
      "8.7     1\n",
      "25.7    1\n",
      "31.0    1\n",
      "4.8     1\n",
      "Name: temp, Length: 192, dtype: int64 \n",
      "\n",
      "RH\n",
      "27     33\n",
      "39     24\n",
      "35     20\n",
      "43     17\n",
      "42     17\n",
      "       ..\n",
      "84      1\n",
      "80      1\n",
      "76      1\n",
      "69      1\n",
      "100     1\n",
      "Name: RH, Length: 75, dtype: int64 \n",
      "\n",
      "wind\n",
      "2.2    53\n",
      "3.1    53\n",
      "4.0    51\n",
      "4.9    48\n",
      "2.7    44\n",
      "4.5    41\n",
      "5.4    41\n",
      "3.6    40\n",
      "1.8    31\n",
      "5.8    24\n",
      "6.3    19\n",
      "7.6    14\n",
      "1.3    14\n",
      "0.9    13\n",
      "6.7     8\n",
      "8.5     8\n",
      "8.0     5\n",
      "7.2     4\n",
      "9.4     4\n",
      "8.9     1\n",
      "0.4     1\n",
      "Name: wind, dtype: int64 \n",
      "\n",
      "rain\n",
      "0.0    509\n",
      "0.8      2\n",
      "0.2      2\n",
      "0.4      1\n",
      "6.4      1\n",
      "1.4      1\n",
      "1.0      1\n",
      "Name: rain, dtype: int64 \n",
      "\n",
      "area\n",
      "0.00     247\n",
      "1.94       3\n",
      "3.71       2\n",
      "0.90       2\n",
      "1.95       2\n",
      "        ... \n",
      "1.26       1\n",
      "2.44       1\n",
      "2.03       1\n",
      "2.21       1\n",
      "24.24      1\n",
      "Name: area, Length: 251, dtype: int64 \n",
      "\n",
      "dayfri\n",
      "0    432\n",
      "1     85\n",
      "Name: dayfri, dtype: int64 \n",
      "\n",
      "daymon\n",
      "0    443\n",
      "1     74\n",
      "Name: daymon, dtype: int64 \n",
      "\n",
      "daysat\n",
      "0    433\n",
      "1     84\n",
      "Name: daysat, dtype: int64 \n",
      "\n",
      "daysun\n",
      "0    422\n",
      "1     95\n",
      "Name: daysun, dtype: int64 \n",
      "\n",
      "daythu\n",
      "0    456\n",
      "1     61\n",
      "Name: daythu, dtype: int64 \n",
      "\n",
      "daytue\n",
      "0    453\n",
      "1     64\n",
      "Name: daytue, dtype: int64 \n",
      "\n",
      "daywed\n",
      "0    463\n",
      "1     54\n",
      "Name: daywed, dtype: int64 \n",
      "\n",
      "monthapr\n",
      "0    508\n",
      "1      9\n",
      "Name: monthapr, dtype: int64 \n",
      "\n",
      "monthaug\n",
      "0    333\n",
      "1    184\n",
      "Name: monthaug, dtype: int64 \n",
      "\n",
      "monthdec\n",
      "0    508\n",
      "1      9\n",
      "Name: monthdec, dtype: int64 \n",
      "\n",
      "monthfeb\n",
      "0    497\n",
      "1     20\n",
      "Name: monthfeb, dtype: int64 \n",
      "\n",
      "monthjan\n",
      "0    515\n",
      "1      2\n",
      "Name: monthjan, dtype: int64 \n",
      "\n",
      "monthjul\n",
      "0    485\n",
      "1     32\n",
      "Name: monthjul, dtype: int64 \n",
      "\n",
      "monthjun\n",
      "0    500\n",
      "1     17\n",
      "Name: monthjun, dtype: int64 \n",
      "\n",
      "monthmar\n",
      "0    463\n",
      "1     54\n",
      "Name: monthmar, dtype: int64 \n",
      "\n",
      "monthmay\n",
      "0    515\n",
      "1      2\n",
      "Name: monthmay, dtype: int64 \n",
      "\n",
      "monthnov\n",
      "0    516\n",
      "1      1\n",
      "Name: monthnov, dtype: int64 \n",
      "\n",
      "monthoct\n",
      "0    502\n",
      "1     15\n",
      "Name: monthoct, dtype: int64 \n",
      "\n",
      "monthsep\n",
      "0    345\n",
      "1    172\n",
      "Name: monthsep, dtype: int64 \n",
      "\n",
      "size_category\n",
      "small    378\n",
      "large    139\n",
      "Name: size_category, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in data.columns:\n",
    "    print(i)\n",
    "    print(data[i].value_counts(),'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e60929ce50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAEGCAYAAABbzE8LAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAKZElEQVR4nO3cb6jdh13H8c+3uZPZaBmkYZR1eCeRgdppRxxIYRZtJaNDfSQK2uAD90TbiYqoFESIT0UIKIx2muJ0yOZARK62aJkK1SXtRq2dEkbKwpR28W/TBzXt1wc5mTWk3b3pOed7T/t6Qcg9h5Pz/RLued/f/Z0/1d0BYP1umF4A4K1KgAGGCDDAEAEGGCLAAEO29nLjm2++ube3t1e0CsCb05kzZ77a3Yevvn5PAd7e3s7p06eXtxXAW0BVPXut652CABgiwABDBBhgiAADDBFggCECDDBEgAGGCDDAEAEGGCLAAEMEGGCIAAMMEWCAIQIMMESAAYYIMMAQAQYYIsAAQwQYYMhaAnzy5MmcPHlyHaMANsZaAryzs5OdnZ11jALYGE5BAAwRYIAhAgwwRIABhggwwBABBhgiwABDBBhgiAADDBFggCECDDBEgAGGCDDAEAEGGCLAAEMEGGCIAAMMEWCAIQIMMESAAYYIMMAQAQYYIsAAQwQYYIgAAwwRYIAhAgwwRIABhggwwBABBhgiwABDBBhgiAADDBFggCECDDBEgAGGCDDAEAEGGCLAAEMEGGCIAAMMEWCAIVvrGPLiiy+uYwzARllLgLt7HWMANopTEABDBBhgiAADDBFggCECDDBEgAGGCDDAEAEGGCLAAEMEGGCIAAMMEWCAIQIMMESAAYYIMMAQAQYYIsAAQwQYYIgAAwwRYIAhAgwwRIABhggwwBABBhgiwABDBBhgiAADDBFggCECDDBEgAGGCDDAEAEGGCLAAEMEGGCIAAMMEWCAIQIMMESAAYbsmwCfPXs299xzT86ePfu6t7tw4ULuv//+XLhwYS0zlzlvmfcFrMcqH7f7JsAnTpzIxYsXc+LEide93alTp/LUU0/l4YcfXsvMZc5b5n0B67HKx+2+CPDZs2dz7ty5JMm5c+de84j0woUL2dnZSXdnZ2fnDf1E2s3MZc5b5n0B67Hqx+2+CPDVR6CvdUR66tSpvPLKK0mSl19++Q39RNrNzGXOW+Z9Aeux6sft1w1wVX2kqk5X1ennn39+qcOvuHIk+lqXr3j00Udz6dKlJMmlS5fyyCOPrHTmMuct876A9Vj14/brBri7P9bdR7v76OHDh5c6/Irt7e3XvXzFXXfdla2trSTJ1tZW7r777pXOXOa8Zd4XsB6rftzui1MQDzzwwOtevuL48eO54YbLKx84cCD33nvvSmcuc94y7wtYj1U/bvdFgI8cOfK1I9Dt7e0cOXLkmrc7dOhQjh07lqrKsWPHcujQoZXOXOa8Zd4XsB6rftzuiwAnl49ADx48+JpHv1ccP348t91221J+Eu1m5jLnLfO+gPVY5eO2unvXNz569GifPn16z0PuvPPOJMljjz22538LsOmq6kx3H736+n1zBAzwViPAAEMEGGCIAAMMEWCAIQIMMESAAYYIMMAQAQYYIsAAQwQYYIgAAwwRYIAhAgwwRIABhggwwBABBhgiwABDBBhgiAADDBFggCECDDBEgAGGCDDAEAEGGCLAAEMEGGCIAAMMEWCAIQIMMESAAYYIMMAQAQYYIsAAQwQYYIgAAwwRYIAhAgwwZGsdQ6pqHWMANspaAnzjjTeuYwzARnEKAmCIAAMMEWCAIQIMMESAAYYIMMAQAQYYIsAAQwQYYIgAAwwRYIAhAgwwRIABhggwwBABBhgiwABDBBhgiAADDBFggCECDDBEgAGGCDDAEAEGGCLAAEMEGGCIAAMMEWCAIQIMMESAAYYIMMAQAQYYIsAAQwQYYIgAAwwRYIAhAgwwRIABhggwwBABBhgiwABDBBhgyNY6hhw7dmwdYwA2yloCfN99961jDMBGcQoCYIgAAwwRYIAhAgwwRIABhggwwBABBhgiwABDBBhgiAADDBFggCECDDBEgAGGCDDAEAEGGCLAAEMEGGCIAAMMEWCAIQIMMKS6e/c3rno+ybPXOevmJF+9zn87bZN3T+w/aZN3TzZ7//20+7d09+Grr9xTgN+Iqjrd3UfXMmzJNnn3xP6TNnn3ZLP334TdnYIAGCLAAEPWGeCPrXHWsm3y7on9J23y7slm77/vd1/bOWAA/j+nIACGCDDAkJUHuKqOVdU/VdXZqvrlVc9bpqr6eFU9V1X/ML3L9aiqd1fVX1XVM1X1dFV9dHqn3aqqt1fV31fVFxa7//r0TntVVQeq6smq+tPpXfaqqs5V1VNV9fmqOj29z15V1Tuq6lNV9cXF9//3Tu90LSs9B1xVB5L8c5K7k5xP8rkkP97d/7iyoUtUVR9M8kKSh7v7O6f32auquiXJLd39RFV9c5IzSX5kE/7/q6qSHOzuF6rqbUn+JslHu/vx4dV2rap+PsnRJDd194en99mLqjqX5Gh375c3MuxJVZ1K8tfd/WBVfUOSG7v7P6b3utqqj4A/kORsd3+pu19K8skkP7zimUvT3Z9N8m/Te1yv7v6X7n5i8fV/J3kmybtmt9qdvuyFxcW3Lf5szDPGVXVrknuSPDi9y1tNVd2U5INJHkqS7n5pP8Y3WX2A35Xky6+6fD4bEoA3m6raTnJ7kr+b3WT3Fr/Cfz7Jc0ke6e6N2T3JbyX5pSSvTC9ynTrJX1TVmar6yPQye/StSZ5P8ruLU0APVtXB6aWuZdUBrmtctzFHMW8WVfVNST6d5Oe6+7+m99mt7n65u787ya1JPlBVG3EaqKo+nOS57j4zvcsbcEd3vz/Jh5L8zOJ03KbYSvL+JL/T3bcnuZhkXz7/tOoAn0/y7lddvjXJV1Y8k1dZnD/9dJJPdPcfT+9zPRa/Pj6W5NjwKrt1R5IfWpxH/WSS76+q359daW+6+yuLv59L8plcPp24Kc4nOf+q35g+lctB3ndWHeDPJfm2qnrP4kT4jyX5kxXPZGHxRNZDSZ7p7t+c3mcvqupwVb1j8fU3JrkryRdnt9qd7v6V7r61u7dz+Xv+L7v7J4bX2rWqOrh40jaLX91/MMnGvBKou/81yZer6r2Lq34gyb584nlrlXfe3Zeq6meT/HmSA0k+3t1Pr3LmMlXVHya5M8nNVXU+ya9190OzW+3JHUl+MslTi3OpSfKr3f1ngzvt1i1JTi1eSXNDkj/q7o17OdeGemeSz1z++Z2tJH/Q3TuzK+3ZfUk+sTjw+1KSnxre55q8FRlgiHfCAQwRYIAhAgwwRIABhggwwBAB5k1j8ZbTb5/eA3bLy9DYKIs3l1R3b+pnLMDXOAJm36uq7cVnuv52kieSPFRVp6/+nOCqeqyqji6+fqGqfmPxecKPV9U7p/aH1yLAbIr35vLnMt+e5Be6+2iS9yX5vqp63zVufzDJ4939XUk+m+Sn17cq7I4AsymefdWHsf9oVT2R5Mkk35HkWud9X0py5a3LZ5Jsr3xD2KOVfhYELNHFJKmq9yT5xSTf093/XlW/l+Tt17j9//T/PcHxcnyvsw85AmbT3JTLMf7PxXndDw3vA9fNUQEbpbu/UFVPJnk6lz/l6m+HV4Lr5mVoAEOcggAYIsAAQwQYYIgAAwwRYIAhAgwwRIABhvwvhQjgPzwqfqMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(data['rain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e60930bfd0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(data['FFMC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e6093ce4f0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAEGCAYAAABbzE8LAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAANx0lEQVR4nO3df2zcdR3H8de7va78mAgbk2yl8SAlGv4gCFWZGF0Gw241gokoCWQzCIub6abGGAj7YzP7R2OMiAm4zB/DnxEkSNhY+KURhvxodU4Q2Q6pbjqlu3Zuk2y017d/fL89bv3B2m5377vr85E0/d7n7nvf7+e723N332tv5u4CAFReQ/QOAMBMRYABIAgBBoAgBBgAghBgAAiSmcqNzz33XM9ms2XaFQCoTz09PQfcfd7o8SkFOJvNqru7+9TtFQDMAGb29/HGOQUBAEEIMAAEIcAAEIQAA0AQAgwAQQgwAAQhwAAQhAADQBACDABBCDAABCHAABCEAANAEAIMAEEIMAAEIcAAEIQAA0AQAgwAQQgwAAQhwAAQZEr/J9x03XLLLTp48KBaWlrU1tamrq6uSmwWAKpaRQK8f/9+HfnfG+obOFSJzQFATajcKYjGjApnzKnY5gCg2nEOGACCEGAACEKAASAIAQaAIAQYAIIQYAAIQoABIAgBBoAgBBgAghBgAAhCgAEgCAEGgCAEGACCEGAACEKAASAIAQaAIAQYAIIQYAAIQoABIAgBBoAgBBgAghBgAAhCgAEgCAEGgCAEGACCEGAACEKAASAIAQaAIAQYAIIQYAAIQoABIAgBBoAgBBgAghBgAAhCgAEgCAEGgCAEGACCEGAACEKAASAIAQaAIAQYAIJkKrGRY8eOScPDxct33XWXJKmrq6sSmweAqlSRAA8PD0vuxcu5XK4SmwWAqsYpCAAIQoABIAgBBoAgBBgAghBgAAhCgAEgCAEGgCAEGACCEGAACEKAASAIAQaAIAQYAIIQYAAIQoABIAgBBoAgBBgAghBgAAhCgAEgCAEGgCAEGACCEGAACEKAASAIAQaAIAQYAIIQYAAIQoABIAgBBoAgBBgAghBgAAhCgAEgCAEGgCAEGACCEGAACEKAASAIAQaAIAQYAIIQYAAIQoABIEhYgPv7+7Vo0aIJv6655hotWbJEixYt0o033qiOjg7dfPPNWrVqlZ588kktXrxYPT09yufzWr16tVauXKlbb71Vq1evVj6fVy6XU2dnp3K53JT2K5/Pa82aNcrn8xOOj15etWpVcbsTrT8dp/K+ULt4HMQq5/FvXL9+/aRvvGnTpvUrV66c8ka2bNkid8mbZ2vBObMlSbt3737bdQqFgoaHhyVJhw8f1tDQkAYGBnTgwAHt2LFDhUJBzzzzjA4dOqSnn35a+Xxe/f396uvr07Fjx3Tfffepr69Pu3bt0nXXXTfpfb3nnnv01FNP6ejRo1q4cOG44zt37jxueceOHcXtll5Xuv50TLQvmFl4HMQ6Fcd/w4YN+9evX79p9HjIM+D+/v6TWn9oaEiSdOTIEW3dunXM9Vu3blVvb68kqbe3d9LPgvP5vLZv3y531/bt24v/4pWOP/LII8ctb9u2rbj+tm3bxl1/OibaF8wsPA5ilfv4VzTADUcPKZfLae/evafsPguFwpixkUCP2Lhx46Tua8uWLcVn3YVCQffee++Y8cHBQQ0ODhaXS7dVel3p+tMx0b5gZuFxEKvcx/+EATazlWbWbWbdfX19p3TjlTLybPhEHn/88WJQh4aG9Nhjj40Zd3e5e3F5tJGx0vWnY6J9wczC4yBWuY//CQPs7pvcvd3d2+fNm3dSGxs+7Sy1tbWd1H1MRzabndTtrr76amUyGUlSJpPRkiVLxoybmcysuDzayFjp+tMx0b5gZuFxEKvcxz/kHHBra+spu6/GxsYxYyMHbMS6desmdV8rVqxQQ0ND8X6XL18+ZrypqUlNTU3F5dJtlV5Xuv50TLQvmFl4HMQq9/EPCfCcOXNOav2R6M2ePVudnZ1jru/s7Cw+681ms5N+1j137lx1dHTIzNTR0aG5c+eOGV+6dOlxy8uWLSuuv2zZsnHXn46J9gUzC4+DWOU+/pkT36Q8Wltb3/bNuFmzZsndNTg4qJaWFuXzeS1YsEDNzc26/vrrtXHjRm3YsEHZbFa5XE5DQ0NydzU1NWn58uUaGBjQ2rVrJ/3sd8SKFSvU29s75l+60eOly3v27JGZjXvdyZhoXzCz8DiIVc7jb+O9kTSR9vZ27+7unvJGFi9erMKwq/CO83T5hecVx++8884p3xcA1Boz63H39tHj/CoyAAQhwAAQhAADQBACDABBCDAABCHAABCEAANAEAIMAEEIMAAEIcAAEIQAA0AQAgwAQQgwAAQhwAAQhAADQBACDABBCDAABCHAABCEAANAEAIMAEEIMAAEIcAAEIQAA0AQAgwAQQgwAAQhwAAQhAADQBACDABBCDAABCHAABCEAANAEAIMAEEIMAAEIcAAEIQAA0AQAgwAQQgwAAQhwAAQJFOJjTQ0NKjgw8XLbW1tldgsAFS1igS4ublZg0ffLF7u6uqqxGYBoKpxCgIAghBgAAhCgAEgCAEGgCAEGACCEGAACEKAASAIAQaAIAQYAIIQYAAIQoABIAgBBoAgBBgAghBgAAhCgAEgCAEGgCAEGACCEGAACEKAASAIAQaAIAQYAIIQYAAIQoABIAgBBoAgBBgAghBgAAhCgAEgCAEGgCAEGACCEGAACEKAASAIAQaAIAQYAIIQYAAIQoABIAgBBoAgBBgAghBgAAhCgAEgCAEGgCCVC3BhSI1v9FdscwBQ7TKV2Mj8+fN18OBBtbS0qK2trRKbBICqV5EAb968uRKbAYCawjlgAAhCgAEgCAEGgCAEGACCEGAACEKAASAIAQaAIAQYAIIQYAAIQoABIAgBBoAgBBgAghBgAAhCgAEgCAEGgCAEGACCEGAACEKAASAIAQaAIAQYAIKYu0/+xmZ9kv4+zW2dK+nANNetBcyvdtXz3CTmVw3e7e7zRg9OKcAnw8y63b29IhsLwPxqVz3PTWJ+1YxTEAAQhAADQJBKBnhTBbcVgfnVrnqem8T8qlbFzgEDAI7HKQgACEKAASBI2QNsZh1m9oqZ5czstnJvrxzMrNXMfmNmL5vZS2a2Nh2fY2aPmdme9Ps5Jevcns75FTP7WNzeT46ZNZrZH83s4fRy3cxNkszsbDO738z+mv45LqyXOZrZl9LH5Ytm9nMzO62W52ZmPzCz183sxZKxKc/HzC43sz+n133HzKzSczkhdy/bl6RGSa9KulDSLEl/knRxObdZpnnMl3RZuvwOSbslXSzpG5JuS8dvk/T1dPnidK7Nki5Ij0Fj9DxOMMcvS/qZpIfTy3Uzt3S/t0i6JV2eJensepijpBZJr0k6Pb38S0mfreW5SfqIpMskvVgyNuX5SHpe0kJJJukRSUuj5zb6q9zPgD8gKefuf3P3NyX9QtK1Zd7mKefu+939D+nyYUkvK3ngX6vkL7bS79ely9dK+oW7H3P31yTllByLqmRm50vqlLS5ZLgu5iZJZnaWkr/U35ckd3/T3Q+qfuaYkXS6mWUknSHpX6rhubn77yT1jxqe0nzMbL6ks9z9957U+N6SdapGuQPcImlvyeV96VjNMrOspPdJek7See6+X0oiLeld6c1qbd7flvRVScMlY/UyNyl5BdYn6YfpaZbNZnam6mCO7v5PSd+U9A9J+yX9190fVR3MbZSpzqclXR49XlXKHeDxzrnU7M+9mdlsSb+S9EV3P/R2Nx1nrCrnbWYfl/S6u/dMdpVxxqpybiUySl7S3u3u75P0PyUvYydSM3NMz4Veq+Tl9wJJZ5rZTW+3yjhjVTm3SZpoPjUxz3IHeJ+k1pLL5yt5eVRzzKxJSXx/6u4PpMP/SV/qKP3+ejpeS/O+UtInzKxXySmixWb2E9XH3Ebsk7TP3Z9LL9+vJMj1MMerJb3m7n3uPijpAUkfUn3MrdRU57MvXR49XlXKHeAXJF1kZheY2SxJN0h6qMzbPOXSd0+/L+lld/9WyVUPSVqRLq+Q9OuS8RvMrNnMLpB0kZI3BKqOu9/u7ue7e1bJn8+T7n6T6mBuI9z935L2mtl70qGrJP1F9THHf0i6wszOSB+nVyl5j6Ie5lZqSvNJT1McNrMr0uOyvGSd6lGBdzSXKfmpgVcl3RH9ruM05/BhJS9fdknamX4tkzRX0hOS9qTf55Ssc0c651dUhe++TjDPRXrrpyDqbW6XSupO/wwflHROvcxR0gZJf5X0oqQfK/mJgJqdm6SfKzmfPajkmeznpjMfSe3pMXlV0neV/uZvNX3xq8gAEITfhAOAIAQYAIIQYAAIQoABIAgBBoAgBBgAghBg1Dwza4zeB2A6CDCqnpk9aGY96WferkzHjpjZ18zsOUkLzewmM3vezHaa2fdGomxmd5tZd7ruhtCJAKMQYNSCm939ciW/2bTGzOZKOlPJ58V+UFJe0mckXenul0oqSLoxXfcOd2+XdImkj5rZJZXffWB8megdACZhjZl9Ml1uVfL7/gUlH44kJZ9/cLmkF9L/9OB0vfVhLZ9OnzVnlHyw/sVKfh0ZCEeAUdXMbJGST/xa6O5vmNlvJZ0m6ai7F0ZuJmmLu98+at0LJH1F0vvdfcDMfpSuC1QFTkGg2r1T0kAa3/dKumKc2zwh6VNm9i6p+P+HvVvSWUo++/e/ZnaepKWV2mlgMngGjGq3XdLnzWyXkk+7enb0Ddz9L2a2TtKjZtag5FO0vuDuz5rZHyW9JOlvknZUcL+BE+LT0AAgCKcgACAIAQaAIAQYAIIQYAAIQoABIAgBBoAgBBgAgvwft4Y6U90pVsIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(data['area'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e609428490>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(data['ISI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['rain']=data['rain'].loc[data.rain<2]\n",
    "data['FFMC']=data['FFMC'].loc[data.FFMC>80]\n",
    "data['ISI']=data['ISI'].loc[data.ISI<30]\n",
    "data['area']=data['area'].loc[data.area<400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>area</th>\n",
       "      <th>dayfri</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>32</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.44</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>71</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.29</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.2</td>\n",
       "      <td>70</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.16</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>94.4</td>\n",
       "      <td>146.0</td>\n",
       "      <td>614.7</td>\n",
       "      <td>11.3</td>\n",
       "      <td>25.6</td>\n",
       "      <td>42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>106.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>11.8</td>\n",
       "      <td>31</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     FFMC    DMC     DC   ISI  temp  RH  wind  rain   area  dayfri  ...  \\\n",
       "0    86.2   26.2   94.3   5.1   8.2  51   6.7   0.0   0.00       1  ...   \n",
       "1    90.6   35.4  669.1   6.7  18.0  33   0.9   0.0   0.00       0  ...   \n",
       "2    90.6   43.7  686.9   6.7  14.6  33   1.3   0.0   0.00       0  ...   \n",
       "3    91.7   33.3   77.5   9.0   8.3  97   4.0   0.2   0.00       1  ...   \n",
       "4    89.3   51.3  102.2   9.6  11.4  99   1.8   0.0   0.00       0  ...   \n",
       "..    ...    ...    ...   ...   ...  ..   ...   ...    ...     ...  ...   \n",
       "512  81.6   56.7  665.6   1.9  27.8  32   2.7   0.0   6.44       0  ...   \n",
       "513  81.6   56.7  665.6   1.9  21.9  71   5.8   0.0  54.29       0  ...   \n",
       "514  81.6   56.7  665.6   1.9  21.2  70   6.7   0.0  11.16       0  ...   \n",
       "515  94.4  146.0  614.7  11.3  25.6  42   4.0   0.0   0.00       0  ...   \n",
       "516   NaN    3.0  106.7   1.1  11.8  31   4.5   0.0   0.00       0  ...   \n",
       "\n",
       "     monthfeb  monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  \\\n",
       "0           0         0         0         0         1         0         0   \n",
       "1           0         0         0         0         0         0         0   \n",
       "2           0         0         0         0         0         0         0   \n",
       "3           0         0         0         0         1         0         0   \n",
       "4           0         0         0         0         1         0         0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512         0         0         0         0         0         0         0   \n",
       "513         0         0         0         0         0         0         0   \n",
       "514         0         0         0         0         0         0         0   \n",
       "515         0         0         0         0         0         0         0   \n",
       "516         0         0         0         0         0         0         1   \n",
       "\n",
       "     monthoct  monthsep  size_category  \n",
       "0           0         0          small  \n",
       "1           1         0          small  \n",
       "2           1         0          small  \n",
       "3           0         0          small  \n",
       "4           0         0          small  \n",
       "..        ...       ...            ...  \n",
       "512         0         0          large  \n",
       "513         0         0          large  \n",
       "514         0         0          large  \n",
       "515         0         0          small  \n",
       "516         0         0          small  \n",
       "\n",
       "[517 rows x 29 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(501, 29)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=data.dropna(axis=0)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-34-aca166d938dd>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['size_category']= le.fit_transform(data['size_category'])\n"
     ]
    }
   ],
   "source": [
    "# feature Encoding\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "le=LabelEncoder()\n",
    "data['size_category']= le.fit_transform(data['size_category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature selection Using Decision Tree :\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "dt_model= DecisionTreeRegressor()\n",
    "y=data['area']\n",
    "x=data.drop(['area'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 0,  1,  2,  3,  4,  5,  6, 13, 16, 27], dtype=int64),)\n"
     ]
    }
   ],
   "source": [
    "dt_model.fit(x,y)\n",
    "l=dt_model.feature_importances_>0.01\n",
    "print(np.where(l==True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>daythu</th>\n",
       "      <th>monthsep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>35</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>32</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>71</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.2</td>\n",
       "      <td>70</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>94.4</td>\n",
       "      <td>146.0</td>\n",
       "      <td>614.7</td>\n",
       "      <td>11.3</td>\n",
       "      <td>25.6</td>\n",
       "      <td>42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>501 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     FFMC    DMC     DC   ISI  temp  RH  wind  daythu  monthsep\n",
       "0    86.2   26.2   94.3   5.1   8.2  51   6.7       0         0\n",
       "1    90.6   35.4  669.1   6.7  18.0  33   0.9       0         0\n",
       "2    90.6   43.7  686.9   6.7  14.6  33   1.3       0         0\n",
       "3    91.7   33.3   77.5   9.0   8.3  97   4.0       0         0\n",
       "4    89.3   51.3  102.2   9.6  11.4  99   1.8       0         0\n",
       "..    ...    ...    ...   ...   ...  ..   ...     ...       ...\n",
       "511  81.6   56.7  665.6   1.9  27.8  35   2.7       0         0\n",
       "512  81.6   56.7  665.6   1.9  27.8  32   2.7       0         0\n",
       "513  81.6   56.7  665.6   1.9  21.9  71   5.8       0         0\n",
       "514  81.6   56.7  665.6   1.9  21.2  70   6.7       0         0\n",
       "515  94.4  146.0  614.7  11.3  25.6  42   4.0       0         0\n",
       "\n",
       "[501 rows x 9 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data=data.iloc[:,[ 0,  1,  2,  3,  4,  5,  6, 13, 27]]\n",
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(501, 9)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler=StandardScaler()\n",
    "x_scaled=scaler.fit_transform(new_data)\n",
    "x_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(501, 9)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features=pd.DataFrame(x_scaled,columns=new_data.columns)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: h5py in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from keras) (1.6.3)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from keras) (5.3.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from keras) (1.18.5)\n",
      "Requirement already satisfied: six in c:\\users\\lenovo\\appdata\\roaming\\python\\python38\\site-packages (from h5py->keras) (1.13.0)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.4.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: c:\\users\\lenovo\\anaconda3\\Include\\UNKNOWN\n",
      "sysconfig: c:\\users\\lenovo\\anaconda3\\Include\n",
      "WARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\n",
      "WARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: c:\\users\\lenovo\\anaconda3\\Include\\UNKNOWN\n",
      "sysconfig: c:\\users\\lenovo\\anaconda3\\Include\n",
      "WARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\n",
      "WARNING: You are using pip version 21.1; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\lenovo\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "! pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam,Adadelta\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV,KFold,cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold=KFold(n_splits=10)\n",
    "def create_model():\n",
    "    model=Sequential([Dense(12,kernel_initializer='normal',activation='relu'),Dense(8,kernel_initializer='normal',activation='relu'),Dense(1,kernel_initializer='normal')])\n",
    "    adam=Adam(lr=0.01)\n",
    "    model.compile(loss='mean_squared_error',optimizer=adam)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 [==============================] - 19s 1ms/step - loss: 1269.6191\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 931us/step - loss: 728.3505\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 576.3844\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 644.8500\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 800.4948\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 783.6508\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 851.0367\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 771.2363\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 882.4910\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 420.3222\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1369.8542\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 693.7135\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 920.1027\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 733.0253\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 693.0360\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 617.8851\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 826.9970\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 723.4808\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 774.0832\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 579.8739\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 689.9037\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 612.4450\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 790.5450\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 618.0638\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 467.6470\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 882.7891\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 474.5263\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 652.1564\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 986.9331\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 805.6749\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1022.9319\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 732.4779\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 798.2108\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 607.5010\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1094.1361\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 838.3125\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 627.2149\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 533.3908\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 722.0077\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 656.7420\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 693.4905\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 681.0917\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 627.8756\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 879.3416\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 726.6911\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 813.9793\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 802.8323\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 878.7557\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 817.9303\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 524.0372\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 606.2724\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 723.3554\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 642.3356\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 623.1908\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 551.9660\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 691.7558\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 433.2684\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 611.0718\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 844.0962\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 890.8611\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 683.4422\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 621.8617\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 569.7798\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 779.1616\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 543.2295\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 482.1289\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1004.7445\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 708.9926\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1137.2819\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 757.1466\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 665.5697\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 531.6450\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 619.9802\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 420.6715\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 620.0620\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1094.6342\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 640.0090\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 762.6834\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 763.8643\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 641.2213\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 961.5064\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 714.8454\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 825.7893\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 753.1785\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 604.8823\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 914.3633\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 852.2603\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1148.1512\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 738.1248\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 750.2024\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 704.8133\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 658.7876\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 741.5697\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 751.2146\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 557.6161\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 986.4294\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 720.5859\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 444.6141\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1133.5001\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 563.6046\n"
     ]
    }
   ],
   "source": [
    "model= create_model()\n",
    "model_one= model.fit(x_scaled,y,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_one.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.00\n",
       "1       0.00\n",
       "2       0.00\n",
       "3       0.00\n",
       "4       0.00\n",
       "       ...  \n",
       "511     0.00\n",
       "512     6.44\n",
       "513    54.29\n",
       "514    11.16\n",
       "515     0.00\n",
       "Name: area, Length: 501, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-14.069203296996317\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "print(r2_score(y_pred,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'actual value')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(y_pred, y)\n",
    "plt.xlabel(\"predicted value\")\n",
    "plt.ylabel(\"actual value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_scaled, y, test_size=0.25, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 857.9156\n",
      "Epoch 2/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 850.5674\n",
      "Epoch 3/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 850.6102\n",
      "Epoch 4/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 848.6105\n",
      "Epoch 5/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 851.6984\n",
      "Epoch 6/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 846.3168\n",
      "Epoch 7/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 847.9448\n",
      "Epoch 8/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 846.3205\n",
      "Epoch 9/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 847.5787\n",
      "Epoch 10/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 849.1089\n",
      "Epoch 11/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 848.1027\n",
      "Epoch 12/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 845.0682\n",
      "Epoch 13/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 849.3792\n",
      "Epoch 14/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 843.7775\n",
      "Epoch 15/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 844.8315\n",
      "Epoch 16/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 842.8593\n",
      "Epoch 17/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 841.4755\n",
      "Epoch 18/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 843.5614\n",
      "Epoch 19/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 842.4619\n",
      "Epoch 20/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 840.0308\n",
      "Epoch 21/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 841.8792\n",
      "Epoch 22/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 841.3005\n",
      "Epoch 23/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 839.9695\n",
      "Epoch 24/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 840.7281\n",
      "Epoch 25/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 840.4611\n",
      "Epoch 26/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 837.3939\n",
      "Epoch 27/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 841.4398\n",
      "Epoch 28/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 839.8611\n",
      "Epoch 29/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 837.2910\n",
      "Epoch 30/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 835.9318\n",
      "Epoch 31/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 838.1163\n",
      "Epoch 32/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 836.6927\n",
      "Epoch 33/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 838.8521\n",
      "Epoch 34/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 837.8579\n",
      "Epoch 35/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 835.3083\n",
      "Epoch 36/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 836.1104\n",
      "Epoch 37/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 836.0112\n",
      "Epoch 38/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 835.7822\n",
      "Epoch 39/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 834.0954\n",
      "Epoch 40/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 837.0308\n",
      "Epoch 41/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 833.4138\n",
      "Epoch 42/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 835.7564\n",
      "Epoch 43/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 836.2206\n",
      "Epoch 44/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 834.2745\n",
      "Epoch 45/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 832.0596\n",
      "Epoch 46/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 830.3842\n",
      "Epoch 47/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 833.0424\n",
      "Epoch 48/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 835.3868\n",
      "Epoch 49/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 833.2058\n",
      "Epoch 50/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 835.8624\n",
      "Epoch 51/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 831.1241\n",
      "Epoch 52/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 832.8243\n",
      "Epoch 53/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 832.2753\n",
      "Epoch 54/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 830.9504\n",
      "Epoch 55/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 832.7188\n",
      "Epoch 56/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 831.5479\n",
      "Epoch 57/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 829.2491\n",
      "Epoch 58/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 832.8376\n",
      "Epoch 59/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 831.2984\n",
      "Epoch 60/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 829.4905\n",
      "Epoch 61/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 830.9728\n",
      "Epoch 62/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 831.6451\n",
      "Epoch 63/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 829.1624\n",
      "Epoch 64/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 829.0427\n",
      "Epoch 65/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 828.1256\n",
      "Epoch 66/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 827.8513\n",
      "Epoch 67/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 828.3951\n",
      "Epoch 68/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 827.9678\n",
      "Epoch 69/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 827.0187\n",
      "Epoch 70/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 828.8644\n",
      "Epoch 71/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 827.5724\n",
      "Epoch 72/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 828.1331\n",
      "Epoch 73/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 827.0065\n",
      "Epoch 74/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 827.2117\n",
      "Epoch 75/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 828.2379\n",
      "Epoch 76/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 825.9636\n",
      "Epoch 77/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 826.4484\n",
      "Epoch 78/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 826.3032\n",
      "Epoch 79/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 828.8754\n",
      "Epoch 80/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 826.0090\n",
      "Epoch 81/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 825.0237\n",
      "Epoch 82/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 830.1414\n",
      "Epoch 83/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 828.5550\n",
      "Epoch 84/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 827.1736\n",
      "Epoch 85/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 826.9609\n",
      "Epoch 86/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 827.3818\n",
      "Epoch 87/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 825.4752\n",
      "Epoch 88/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 833.4352\n",
      "Epoch 89/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 825.3094\n",
      "Epoch 90/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 826.1651\n",
      "Epoch 91/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 824.5842\n",
      "Epoch 92/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 824.6757\n",
      "Epoch 93/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 823.7087\n",
      "Epoch 94/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 824.4864\n",
      "Epoch 95/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 825.9560\n",
      "Epoch 96/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 823.0486\n",
      "Epoch 97/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 829.7866\n",
      "Epoch 98/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 821.3702\n",
      "Epoch 99/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 825.5584\n",
      "Epoch 100/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 822.9500\n",
      "Epoch 101/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 822.0716\n",
      "Epoch 102/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 827.2090\n",
      "Epoch 103/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 823.7166\n",
      "Epoch 104/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 821.0150\n",
      "Epoch 105/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 826.5372\n",
      "Epoch 106/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 824.9316\n",
      "Epoch 107/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 824.3685\n",
      "Epoch 108/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 822.2849\n",
      "Epoch 109/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 823.6661\n",
      "Epoch 110/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 822.9384\n",
      "Epoch 111/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 825.8422\n",
      "Epoch 112/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 823.1639\n",
      "Epoch 113/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 823.1860\n",
      "Epoch 114/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 822.8983\n",
      "Epoch 115/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 824.4765\n",
      "Epoch 116/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 821.2698\n",
      "Epoch 117/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 824.5544\n",
      "Epoch 118/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 821.2213\n",
      "Epoch 119/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 829.8461\n",
      "Epoch 120/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 824.0940\n",
      "Epoch 121/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 822.1638\n",
      "Epoch 122/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 821.2657\n",
      "Epoch 123/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 822.6223\n",
      "Epoch 124/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 824.0012\n",
      "Epoch 125/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 821.7576\n",
      "Epoch 126/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 823.5004\n",
      "Epoch 127/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 822.1006\n",
      "Epoch 128/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 820.7332\n",
      "Epoch 129/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 821.2855\n",
      "Epoch 130/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 821.6284\n",
      "Epoch 131/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 820.1786\n",
      "Epoch 132/500\n",
      "12/12 [==============================] - ETA: 0s - loss: 216.501 - 0s 1ms/step - loss: 822.1381\n",
      "Epoch 133/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 819.9991\n",
      "Epoch 134/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 821.1312\n",
      "Epoch 135/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 823.7755\n",
      "Epoch 136/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 819.3917\n",
      "Epoch 137/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 822.7754\n",
      "Epoch 138/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 822.7712\n",
      "Epoch 139/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 822.8837\n",
      "Epoch 140/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 823.8439\n",
      "Epoch 141/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 820.1494\n",
      "Epoch 142/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 823.2017\n",
      "Epoch 143/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 817.2266\n",
      "Epoch 144/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 819.3671\n",
      "Epoch 145/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 820.6766\n",
      "Epoch 146/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 823.9354\n",
      "Epoch 147/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 820.6886\n",
      "Epoch 148/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 824.8106\n",
      "Epoch 149/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 823.5358\n",
      "Epoch 150/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 822.6968\n",
      "Epoch 151/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 818.9464\n",
      "Epoch 152/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 823.5292\n",
      "Epoch 153/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 821.3777\n",
      "Epoch 154/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 823.5971\n",
      "Epoch 155/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 818.9176\n",
      "Epoch 156/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 819.0745\n",
      "Epoch 157/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 822.4456\n",
      "Epoch 158/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 819.4612\n",
      "Epoch 159/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 819.6929\n",
      "Epoch 160/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 818.9916\n",
      "Epoch 161/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 821.2138\n",
      "Epoch 162/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 817.7254\n",
      "Epoch 163/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 822.7253\n",
      "Epoch 164/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 827.3771\n",
      "Epoch 165/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 823.3410\n",
      "Epoch 166/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 819.4177\n",
      "Epoch 167/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 823.6353\n",
      "Epoch 168/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 817.3904\n",
      "Epoch 169/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 821.2396\n",
      "Epoch 170/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 819.1656\n",
      "Epoch 171/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 821.3706\n",
      "Epoch 172/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 821.7551\n",
      "Epoch 173/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 819.4646\n",
      "Epoch 174/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 820.5144\n",
      "Epoch 175/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 820.8233\n",
      "Epoch 176/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 822.0372\n",
      "Epoch 177/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 817.7706\n",
      "Epoch 178/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 819.7216\n",
      "Epoch 179/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 822.6864\n",
      "Epoch 180/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 816.9827\n",
      "Epoch 181/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 824.2422\n",
      "Epoch 182/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 819.9239\n",
      "Epoch 183/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 822.4658\n",
      "Epoch 184/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 819.3851\n",
      "Epoch 185/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 821.8954\n",
      "Epoch 186/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 817.4436\n",
      "Epoch 187/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 818.0529\n",
      "Epoch 188/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 818.8353\n",
      "Epoch 189/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 817.7772\n",
      "Epoch 190/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 819.3727\n",
      "Epoch 191/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 820.7849\n",
      "Epoch 192/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 819.8874\n",
      "Epoch 193/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 816.2968\n",
      "Epoch 194/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 820.0505\n",
      "Epoch 195/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 818.7497\n",
      "Epoch 196/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 1ms/step - loss: 816.5080\n",
      "Epoch 197/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 817.8252\n",
      "Epoch 198/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 820.7472\n",
      "Epoch 199/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 820.5468\n",
      "Epoch 200/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 815.6407\n",
      "Epoch 201/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 818.4647\n",
      "Epoch 202/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 821.3248\n",
      "Epoch 203/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 817.0979\n",
      "Epoch 204/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 820.1646\n",
      "Epoch 205/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 818.6837\n",
      "Epoch 206/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 818.8832\n",
      "Epoch 207/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 817.8095\n",
      "Epoch 208/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 817.0029\n",
      "Epoch 209/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 820.0659\n",
      "Epoch 210/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 818.1376\n",
      "Epoch 211/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 821.2546\n",
      "Epoch 212/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 817.6864\n",
      "Epoch 213/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 819.6606\n",
      "Epoch 214/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 815.5695\n",
      "Epoch 215/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 818.4158\n",
      "Epoch 216/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 816.5129\n",
      "Epoch 217/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 816.4033\n",
      "Epoch 218/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 817.5319\n",
      "Epoch 219/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 818.0618\n",
      "Epoch 220/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 828.8448\n",
      "Epoch 221/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 818.8116\n",
      "Epoch 222/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 816.7342\n",
      "Epoch 223/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 817.7188\n",
      "Epoch 224/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 818.3124\n",
      "Epoch 225/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 817.0410\n",
      "Epoch 226/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 818.7562\n",
      "Epoch 227/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 818.6293\n",
      "Epoch 228/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 815.5076\n",
      "Epoch 229/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 818.4322\n",
      "Epoch 230/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 815.1321\n",
      "Epoch 231/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 820.0329\n",
      "Epoch 232/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 818.4814\n",
      "Epoch 233/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 816.4365\n",
      "Epoch 234/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 816.7418\n",
      "Epoch 235/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 816.3985\n",
      "Epoch 236/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 819.7751\n",
      "Epoch 237/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 816.3248\n",
      "Epoch 238/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 815.5527\n",
      "Epoch 239/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 816.6744\n",
      "Epoch 240/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 816.3812\n",
      "Epoch 241/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 816.1031\n",
      "Epoch 242/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 817.4391\n",
      "Epoch 243/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 816.9182\n",
      "Epoch 244/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 818.3883\n",
      "Epoch 245/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 814.9305\n",
      "Epoch 246/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 816.3509\n",
      "Epoch 247/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 820.7432\n",
      "Epoch 248/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 812.9827\n",
      "Epoch 249/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 816.6260\n",
      "Epoch 250/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 818.0725\n",
      "Epoch 251/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 818.4620\n",
      "Epoch 252/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 822.1886\n",
      "Epoch 253/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 822.4705\n",
      "Epoch 254/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 814.7338\n",
      "Epoch 255/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 814.8526\n",
      "Epoch 256/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 814.8656\n",
      "Epoch 257/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 815.7252\n",
      "Epoch 258/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 817.2721\n",
      "Epoch 259/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 818.6613\n",
      "Epoch 260/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 815.8624\n",
      "Epoch 261/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 822.4828\n",
      "Epoch 262/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 817.8444\n",
      "Epoch 263/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 815.5450\n",
      "Epoch 264/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 816.2406\n",
      "Epoch 265/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 816.2521\n",
      "Epoch 266/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 814.5359\n",
      "Epoch 267/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 816.4431\n",
      "Epoch 268/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 814.7530\n",
      "Epoch 269/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 813.2103\n",
      "Epoch 270/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 814.3752\n",
      "Epoch 271/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 815.9809\n",
      "Epoch 272/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 815.4238\n",
      "Epoch 273/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 814.2044\n",
      "Epoch 274/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 816.2823\n",
      "Epoch 275/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 813.4833\n",
      "Epoch 276/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 816.8766\n",
      "Epoch 277/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 817.8195\n",
      "Epoch 278/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 817.3935\n",
      "Epoch 279/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 814.4220\n",
      "Epoch 280/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 816.2643\n",
      "Epoch 281/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 815.1729\n",
      "Epoch 282/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 816.2909\n",
      "Epoch 283/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 816.8500\n",
      "Epoch 284/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 813.1407\n",
      "Epoch 285/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 817.4059\n",
      "Epoch 286/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 819.0470\n",
      "Epoch 287/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 813.9041\n",
      "Epoch 288/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 818.8293\n",
      "Epoch 289/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 816.9948\n",
      "Epoch 290/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 816.7833\n",
      "Epoch 291/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 812.4311\n",
      "Epoch 292/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 815.4025\n",
      "Epoch 293/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 813.5744\n",
      "Epoch 294/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 813.1727\n",
      "Epoch 295/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 815.6624\n",
      "Epoch 296/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 815.4512\n",
      "Epoch 297/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 815.6841\n",
      "Epoch 298/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 818.6954\n",
      "Epoch 299/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 815.9073\n",
      "Epoch 300/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 816.8190\n",
      "Epoch 301/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 817.7732\n",
      "Epoch 302/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 813.6393\n",
      "Epoch 303/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 819.0041\n",
      "Epoch 304/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 811.5069\n",
      "Epoch 305/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 817.5242\n",
      "Epoch 306/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 813.5402\n",
      "Epoch 307/500\n",
      "12/12 [==============================] - ETA: 0s - loss: 451.099 - 0s 1ms/step - loss: 814.3212\n",
      "Epoch 308/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 811.1718\n",
      "Epoch 309/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 817.0725\n",
      "Epoch 310/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 817.6884\n",
      "Epoch 311/500\n",
      "12/12 [==============================] - ETA: 0s - loss: 945.530 - 0s 1ms/step - loss: 814.7623\n",
      "Epoch 312/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 813.0746\n",
      "Epoch 313/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 810.9636\n",
      "Epoch 314/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 813.1275\n",
      "Epoch 315/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 810.9311\n",
      "Epoch 316/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 812.4379\n",
      "Epoch 317/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 807.9149\n",
      "Epoch 318/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 807.4957\n",
      "Epoch 319/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 806.9949\n",
      "Epoch 320/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 807.6053\n",
      "Epoch 321/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 804.8762\n",
      "Epoch 322/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 806.7377\n",
      "Epoch 323/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 802.6067\n",
      "Epoch 324/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 802.8165\n",
      "Epoch 325/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 802.8830\n",
      "Epoch 326/500\n",
      "12/12 [==============================] - ETA: 0s - loss: 2003.44 - 0s 1ms/step - loss: 800.6268\n",
      "Epoch 327/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 798.2747\n",
      "Epoch 328/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 805.7557\n",
      "Epoch 329/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 796.7183\n",
      "Epoch 330/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 797.0735\n",
      "Epoch 331/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 804.0059\n",
      "Epoch 332/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 798.8832\n",
      "Epoch 333/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 795.9375\n",
      "Epoch 334/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 793.6830\n",
      "Epoch 335/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 788.6704\n",
      "Epoch 336/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 788.5787\n",
      "Epoch 337/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 789.7944\n",
      "Epoch 338/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 786.2753\n",
      "Epoch 339/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 790.0291\n",
      "Epoch 340/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 785.2188\n",
      "Epoch 341/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 781.2621\n",
      "Epoch 342/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 780.0972\n",
      "Epoch 343/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 781.1378\n",
      "Epoch 344/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 778.6014\n",
      "Epoch 345/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 776.9294\n",
      "Epoch 346/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 775.5997\n",
      "Epoch 347/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 772.4828\n",
      "Epoch 348/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 772.3077\n",
      "Epoch 349/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 774.1248\n",
      "Epoch 350/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 773.1602\n",
      "Epoch 351/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 765.6943\n",
      "Epoch 352/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 766.3934\n",
      "Epoch 353/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 770.1937\n",
      "Epoch 354/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 760.6202\n",
      "Epoch 355/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 768.4801\n",
      "Epoch 356/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 758.0451\n",
      "Epoch 357/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 760.1613\n",
      "Epoch 358/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 765.9428\n",
      "Epoch 359/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 753.6245\n",
      "Epoch 360/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 753.9431\n",
      "Epoch 361/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 748.1793\n",
      "Epoch 362/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 745.4007\n",
      "Epoch 363/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 745.7565\n",
      "Epoch 364/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 747.1255\n",
      "Epoch 365/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 747.4049\n",
      "Epoch 366/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 749.4658\n",
      "Epoch 367/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 743.4541\n",
      "Epoch 368/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 743.6652\n",
      "Epoch 369/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 737.1441\n",
      "Epoch 370/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 737.8643\n",
      "Epoch 371/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 741.9954\n",
      "Epoch 372/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 738.8550\n",
      "Epoch 373/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 732.7334\n",
      "Epoch 374/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 730.9366\n",
      "Epoch 375/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 730.3214\n",
      "Epoch 376/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 730.1426\n",
      "Epoch 377/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 745.9459\n",
      "Epoch 378/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 724.7704\n",
      "Epoch 379/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 726.1313\n",
      "Epoch 380/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 726.1874\n",
      "Epoch 381/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 717.4914\n",
      "Epoch 382/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 732.2682\n",
      "Epoch 383/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 733.4446\n",
      "Epoch 384/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 721.8275\n",
      "Epoch 385/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 713.7838\n",
      "Epoch 386/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 716.4772\n",
      "Epoch 387/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 710.1674\n",
      "Epoch 388/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 707.5867\n",
      "Epoch 389/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 1ms/step - loss: 709.4293\n",
      "Epoch 390/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 702.6165\n",
      "Epoch 391/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 701.9266\n",
      "Epoch 392/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 697.8675\n",
      "Epoch 393/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 701.5075\n",
      "Epoch 394/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 708.5491\n",
      "Epoch 395/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 715.5249\n",
      "Epoch 396/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 719.5677\n",
      "Epoch 397/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 694.0117\n",
      "Epoch 398/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 704.6317\n",
      "Epoch 399/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 690.2263\n",
      "Epoch 400/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 695.4411\n",
      "Epoch 401/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 683.9144\n",
      "Epoch 402/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 690.2167\n",
      "Epoch 403/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 686.5959\n",
      "Epoch 404/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 682.1419\n",
      "Epoch 405/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 680.5139\n",
      "Epoch 406/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 680.0496\n",
      "Epoch 407/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 676.9222\n",
      "Epoch 408/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 684.6707\n",
      "Epoch 409/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 679.6627\n",
      "Epoch 410/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 676.1692\n",
      "Epoch 411/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 676.1497\n",
      "Epoch 412/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 672.4277\n",
      "Epoch 413/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 669.3777\n",
      "Epoch 414/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 678.3290\n",
      "Epoch 415/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 665.7325\n",
      "Epoch 416/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 666.0045\n",
      "Epoch 417/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 663.6353\n",
      "Epoch 418/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 661.4319\n",
      "Epoch 419/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 659.2471\n",
      "Epoch 420/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 674.1964\n",
      "Epoch 421/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 655.4834\n",
      "Epoch 422/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 655.8959\n",
      "Epoch 423/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 658.0884\n",
      "Epoch 424/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 654.9085\n",
      "Epoch 425/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 646.4220\n",
      "Epoch 426/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 661.6335\n",
      "Epoch 427/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 650.7598\n",
      "Epoch 428/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 647.1617\n",
      "Epoch 429/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 642.9348\n",
      "Epoch 430/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 647.2700\n",
      "Epoch 431/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 648.9299\n",
      "Epoch 432/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 639.6862\n",
      "Epoch 433/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 650.0710\n",
      "Epoch 434/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 636.7231\n",
      "Epoch 435/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 638.7667\n",
      "Epoch 436/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 634.3842\n",
      "Epoch 437/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 638.0316\n",
      "Epoch 438/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 639.2089\n",
      "Epoch 439/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 624.3759\n",
      "Epoch 440/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 645.2178\n",
      "Epoch 441/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 661.6822\n",
      "Epoch 442/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 635.7556\n",
      "Epoch 443/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 639.3883\n",
      "Epoch 444/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 629.9628\n",
      "Epoch 445/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 628.1364\n",
      "Epoch 446/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 623.4791\n",
      "Epoch 447/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 623.1169\n",
      "Epoch 448/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 618.4091\n",
      "Epoch 449/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 617.6531\n",
      "Epoch 450/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 618.7277\n",
      "Epoch 451/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 618.0972\n",
      "Epoch 452/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 629.7747\n",
      "Epoch 453/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 616.2220\n",
      "Epoch 454/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 615.9894\n",
      "Epoch 455/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 610.3040\n",
      "Epoch 456/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 611.7668\n",
      "Epoch 457/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 607.4203\n",
      "Epoch 458/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 608.9097\n",
      "Epoch 459/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 609.2346\n",
      "Epoch 460/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 611.8648\n",
      "Epoch 461/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 614.6844\n",
      "Epoch 462/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 602.1045\n",
      "Epoch 463/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 603.6746\n",
      "Epoch 464/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 613.1133\n",
      "Epoch 465/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 600.2045\n",
      "Epoch 466/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 601.0512\n",
      "Epoch 467/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 593.8599\n",
      "Epoch 468/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 596.7828\n",
      "Epoch 469/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 612.3999\n",
      "Epoch 470/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 620.0643\n",
      "Epoch 471/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 585.6692\n",
      "Epoch 472/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 606.7375\n",
      "Epoch 473/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 601.6490\n",
      "Epoch 474/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 584.8666\n",
      "Epoch 475/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 597.0190\n",
      "Epoch 476/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 607.6675\n",
      "Epoch 477/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 586.9084\n",
      "Epoch 478/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 604.7039\n",
      "Epoch 479/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 574.1697\n",
      "Epoch 480/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 589.3999\n",
      "Epoch 481/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 579.0446\n",
      "Epoch 482/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 588.7908\n",
      "Epoch 483/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 603.9127\n",
      "Epoch 484/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 582.4282\n",
      "Epoch 485/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 579.6906\n",
      "Epoch 486/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 570.3825\n",
      "Epoch 487/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 579.3993\n",
      "Epoch 488/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 571.0414\n",
      "Epoch 489/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 575.1454\n",
      "Epoch 490/500\n",
      "12/12 [==============================] - ETA: 0s - loss: 330.190 - 0s 1ms/step - loss: 566.6710\n",
      "Epoch 491/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 571.5875\n",
      "Epoch 492/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 581.0965\n",
      "Epoch 493/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 576.4820\n",
      "Epoch 494/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 571.9373\n",
      "Epoch 495/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 585.0519\n",
      "Epoch 496/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 582.7430\n",
      "Epoch 497/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 575.6893\n",
      "Epoch 498/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 576.9357\n",
      "Epoch 499/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 573.7237\n",
      "Epoch 500/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 591.5422\n"
     ]
    }
   ],
   "source": [
    "# train data on base model :\n",
    "model_2 = model.fit(np.array(x_train), np.array(y_train), epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy : -0.9063848992845165\n"
     ]
    }
   ],
   "source": [
    "# training accuracy of base model :\n",
    "y_train_pred = model.predict(x_train)\n",
    "print(\"training accuracy :\", r2_score(y_train_pred, y_train))     # 90.63 % training accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing accuracy : -0.8295378729622103\n"
     ]
    }
   ],
   "source": [
    "# testing accuracy :\n",
    "y_test_pred = model.predict(x_test)\n",
    "\n",
    "print(\"testing accuracy :\", r2_score(y_test_pred, y_test)) #82.95 % testing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 192 candidates, totalling 960 fits\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, ephocs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "activation_function is not a legal parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-0773a2e81859>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[0mgrid_result\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_scaled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    734\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1188\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1027\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1028\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1029\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    845\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 847\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    848\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    763\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    253\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    253\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    518\u001b[0m             \u001b[0mcloned_parameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 520\u001b[1;33m         \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mcloned_parameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    521\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mset_params\u001b[1;34m(self, **params)\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m     \"\"\"\n\u001b[1;32m--> 127\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msk_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mcheck_params\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    101\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mparams_name\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'nb_epoch'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m           \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{} is not a legal parameter'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=unused-argument\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: activation_function is not a legal parameter"
     ]
    }
   ],
   "source": [
    "# create general model which is use to find better parameter :\n",
    "def create_model(learning_rate,dropout_rate,activation_function,init,neuron1,neuron2):\n",
    "    m=Sequential()\n",
    "    m.add(Dense(neuron1,input_dim=9,kernel_initializer=init,activation_function=activation_function))\n",
    "    m.add(Dropout(dropout_rate))\n",
    "    m.add(Dense(neuron2,input_dim=neuron1,kernel_initializer=init,activation_function=activation_function))\n",
    "    m.add(Dropout(dropout_rate))\n",
    "    m.add(Dense(1,kernel_initializer='normal'))\n",
    "    adam = Adam(lr = learning_rate)\n",
    "    m.compile(loss = 'mean_squared_error',optimizer = adam)\n",
    "    return m\n",
    "# Create the model\n",
    "\n",
    "model = KerasRegressor(build_fn = create_model,verbose = 0)\n",
    "\n",
    "# Define the grid search parameters\n",
    "\n",
    "batch_size=[10]\n",
    "ephocs=[100,200,300]\n",
    "learning_rate=[0.001,0.01]\n",
    "dropout_rate=[0.0,0.1]\n",
    "activation_function =['relu','linear']\n",
    "init=['uniform','normal']\n",
    "neuron1=[8,14]\n",
    "neuron2=[6,9]\n",
    "\n",
    "# make a dictionary of the grid search parameters\n",
    "param_grid= dict(batch_size=batch_size,ephocs=ephocs,learning_rate=learning_rate,\n",
    "                 dropout_rate=dropout_rate,activation_function =activation_function ,init=init,\n",
    "                 neuron1=neuron1,neuron2=neuron2)\n",
    "\n",
    "# Build and fit the GridSearchCV\n",
    "grid= GridSearchCV(estimator=model,param_grid=param_grid,cv=KFold(),verbose=10)\n",
    "\n",
    "grid_result= grid.fit(np.array(x_scaled),np.array(y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 192 candidates, totalling 960 fits\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-156.192, total=   6.6s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-112.695, total=   3.7s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   10.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-2115.138, total=   3.7s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   13.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-482.773, total=   3.7s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   17.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-1365.118, total=   3.5s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   21.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-156.455, total=   3.3s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   24.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-104.917, total=   3.9s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   28.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-2124.027, total=   3.3s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   31.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-476.687, total=   3.4s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   35.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-1377.278, total=   3.5s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-150.633, total=   3.6s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-107.303, total=   4.3s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-2125.700, total=   3.9s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-473.748, total=   4.1s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-1371.062, total=   3.8s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-155.326, total=   3.9s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-119.628, total=   3.7s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-2113.350, total=   3.9s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-472.992, total=   3.9s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-1371.940, total=   3.8s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-155.920, total=   3.4s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-142.141, total=   3.8s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-2163.174, total=   5.3s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-489.650, total=   3.3s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-1394.038, total=   3.3s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-170.911, total=   3.3s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-238.783, total=   3.6s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-2174.590, total=   3.7s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-507.000, total=   4.2s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-1405.738, total=   6.7s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-189.781, total=   3.3s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-226.269, total=   3.5s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-2149.690, total=   3.4s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-551.048, total=   3.3s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-1390.330, total=   6.3s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-141.528, total=   3.4s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-204.905, total=   4.1s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-2126.949, total=   3.7s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-495.266, total=   3.7s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-1381.321, total=   3.7s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-148.772, total=   3.3s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-103.276, total=   3.5s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-2121.189, total=   3.6s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-469.966, total=   3.9s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-1368.160, total=   3.5s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-154.967, total=   3.8s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-107.509, total=   3.5s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-2122.267, total=   5.2s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-473.502, total=   5.1s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-1374.066, total=   7.3s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-156.163, total=   5.6s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-107.298, total=   4.4s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-2127.606, total=   4.0s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-470.139, total=   4.0s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-1384.621, total=   4.1s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-155.330, total=   3.9s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-115.040, total=   3.8s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-2132.556, total=   4.2s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-490.639, total=   4.7s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-1381.281, total=   6.9s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-180.005, total=   3.4s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-218.783, total=   3.5s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-2170.948, total=   3.8s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-479.490, total=   4.4s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-1393.275, total=   3.8s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-152.746, total=   5.9s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-164.712, total=   4.8s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-2153.353, total=   3.4s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-549.989, total=   3.5s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-1383.781, total=   3.5s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-161.430, total=   3.7s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-267.571, total=   4.1s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-2150.135, total=   3.8s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-574.083, total=   4.2s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-1368.598, total=   3.9s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-152.134, total=   5.6s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-272.642, total=   7.2s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-2145.758, total=   4.0s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-530.223, total=   3.8s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-1418.794, total=   3.6s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-159.740, total=   9.4s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-119.774, total=   6.8s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-2131.230, total=   6.5s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-493.021, total=   9.7s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-1381.226, total=   6.2s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-151.650, total=   6.3s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-111.932, total=   7.2s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-2140.321, total=  12.7s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-483.761, total=   7.4s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-1378.163, total=   9.3s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-158.354, total=   7.0s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-20.508, total=  10.1s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-2140.043, total=   6.7s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-474.345, total=  10.6s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-1397.117, total=   6.2s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-154.294, total=   6.3s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-124.049, total=   6.9s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-2146.047, total=   6.5s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-474.745, total=  11.5s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-1410.709, total=   8.0s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-150.485, total=   5.8s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-348.839, total=   6.2s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-2127.579, total=   6.0s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-558.420, total=  11.9s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-1376.136, total=   6.0s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-1012.721, total=   5.8s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-442.386, total=   6.3s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-2149.473, total=   6.5s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-637.313, total=   6.5s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-1368.099, total=   6.3s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-220.961, total=  10.9s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-701.020, total=   9.4s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-2114.064, total=   6.5s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-747.465, total=  12.3s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-1436.700, total=   5.9s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-773.249, total=   9.6s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-167.390, total=   7.1s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-2215.502, total=   7.0s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-810.670, total=  10.7s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-1247.199, total=   7.5s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-151.095, total=   6.7s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-114.605, total=   6.8s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-2125.968, total=   7.5s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-489.657, total=   6.8s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-1367.600, total=   6.2s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-151.463, total=   6.2s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-123.443, total=   7.2s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-2129.812, total=   7.1s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-471.174, total=  11.6s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-1403.026, total=  11.8s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-154.717, total=   7.7s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-137.116, total=   7.1s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-2149.121, total=   6.6s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-476.775, total=  14.3s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-1399.425, total=   5.9s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-161.276, total=  10.3s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-129.821, total=   6.8s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-2116.613, total=   7.1s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-496.180, total=   7.1s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-1404.335, total=   7.1s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-230.434, total=   7.2s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-243.058, total=   7.1s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-2153.828, total=   6.3s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-609.206, total=  10.9s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-1432.044, total=   7.9s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-227.785, total=   6.1s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-450.070, total=   6.6s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-2062.698, total=   6.5s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-672.533, total=   6.7s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-1395.653, total=  11.6s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-142.220, total=   8.6s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-949.005, total=   6.4s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-2164.389, total=   6.2s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-642.232, total=  13.5s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-1469.045, total=   8.7s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-309.626, total=   6.6s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-631.341, total=   7.0s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-2271.366, total=   7.3s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-511.210, total=   7.0s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-1300.360, total=  11.9s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-145.847, total=   9.1s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-138.839, total=   9.1s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-2137.913, total=   9.8s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-473.718, total=   9.6s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-1385.979, total=  10.2s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-151.903, total=   9.9s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-132.516, total=  16.1s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-2149.234, total=  10.3s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-469.140, total=   9.5s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-1414.868, total=  15.9s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-149.950, total=  10.8s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-125.600, total=   9.5s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-2143.229, total=  15.1s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-488.539, total=  10.1s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-1420.664, total=  13.9s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-155.011, total=  16.2s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-129.388, total=  10.5s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-2138.019, total=  11.0s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-501.722, total=  10.3s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-1399.381, total=   9.9s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-163.100, total=  16.7s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-682.988, total=  13.1s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-2089.527, total=  11.0s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-1046.907, total=   9.0s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-1391.251, total=  17.0s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-457.465, total=  12.1s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-1150.719, total=   9.3s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-2956.159, total=   9.9s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-2568.030, total=  16.1s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-1538.989, total=   9.8s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-322.630, total=   8.9s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-591.645, total=  16.0s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-2049.364, total=   9.0s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-750.992, total=  12.6s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-1472.194, total=  14.1s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-215.177, total=   8.4s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-842.100, total=  16.5s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-2515.090, total=  10.2s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-699.807, total=   8.8s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-1892.096, total=  15.0s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-149.983, total=   8.1s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-134.000, total=   8.8s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-2146.775, total=   9.4s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-483.155, total=  15.2s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-1388.589, total=  10.1s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-153.601, total=   9.0s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-143.358, total=   8.8s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-2148.300, total=   9.8s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-493.755, total=  14.9s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-1403.159, total=   9.2s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-178.814, total=   9.0s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-136.100, total=  16.4s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-2127.927, total=   9.7s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-477.303, total=   9.5s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-1382.732, total=  17.3s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-163.744, total=   9.7s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-150.583, total=   9.9s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-2149.966, total=  14.8s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-486.236, total=   9.4s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-1402.307, total=   9.5s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-148.457, total=  13.6s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-348.743, total=  12.6s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-2086.851, total=   9.0s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-593.018, total=  12.9s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-1366.747, total=   9.8s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-152.215, total=   8.4s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-769.566, total=   8.9s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-2405.971, total=   8.4s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-561.675, total=  14.0s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-1469.698, total=   8.7s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-1159.088, total=   8.6s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-377.896, total=  15.7s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-2326.999, total=   9.2s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-441.252, total=  13.9s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-2478.641, total=  12.6s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-664.645, total=   9.3s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-625.109, total=   9.5s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-2837.360, total=  10.0s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-1061.648, total=  10.7s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-1874.012, total=  10.4s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-144.922, total=   4.4s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-87.620, total=   3.9s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-2120.235, total=   4.4s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-461.876, total=   3.6s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-1358.709, total=   7.1s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-149.031, total=   4.8s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-104.282, total=   4.1s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-2124.735, total=   3.6s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-464.105, total=   3.8s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-1367.688, total=   3.8s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-145.099, total=   3.5s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-91.042, total=   6.8s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-2126.217, total=   6.1s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-470.105, total=   4.1s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-1372.918, total=   4.3s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-139.061, total=   4.0s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-108.674, total=   4.7s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-2126.153, total=   4.0s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-464.476, total=   4.9s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-1378.729, total=   4.6s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-147.052, total=   4.5s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-160.243, total=   4.3s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-2142.301, total=   7.5s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-487.963, total=   4.7s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-1398.823, total=   4.2s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-133.722, total=   3.8s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-239.397, total=   4.2s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-2164.812, total=   5.4s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-502.556, total=   3.9s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-1367.374, total=   6.7s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-135.739, total=   3.8s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-268.825, total=   3.7s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-2146.278, total=   4.3s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-501.309, total=   4.1s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-1363.188, total=   4.3s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-164.560, total=   6.7s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-188.350, total=   5.9s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-2136.948, total=   3.8s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-576.067, total=   3.7s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-1377.210, total=   3.7s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-142.456, total=   3.4s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-96.868, total=   7.6s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-2118.136, total=   6.0s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-469.523, total=   3.5s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-1360.919, total=   3.6s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-151.928, total=   5.6s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-100.419, total=   7.1s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-2117.538, total=   3.5s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-468.095, total=   4.2s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-1354.132, total=   3.6s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-140.804, total=   3.4s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-94.500, total=   6.9s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-2125.112, total=   6.0s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-469.680, total=   3.6s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-1354.913, total=   7.9s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-140.234, total=   5.4s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-102.008, total=   3.8s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-2126.551, total=   3.9s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-479.466, total=   3.9s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-1368.863, total=   4.1s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-159.007, total=   5.9s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-174.199, total=   7.8s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-2156.509, total=   4.7s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-521.513, total=   3.8s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-1372.480, total=   4.2s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-145.491, total=   3.5s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-202.906, total=   6.4s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-2157.127, total=   7.7s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-544.646, total=   4.2s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-1398.382, total=   4.4s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-152.033, total=   3.9s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-233.483, total=   7.0s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-2172.528, total=   7.2s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-540.080, total=   3.5s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-1389.949, total=   3.4s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-140.792, total=   6.3s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-197.730, total=   5.4s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-2181.916, total=   3.7s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-557.769, total=   6.7s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-1384.720, total=   5.9s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-143.412, total=   6.8s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-108.684, total=   7.1s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-2136.607, total=   7.4s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-465.900, total=   6.8s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-1396.887, total=   6.5s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-142.997, total=  10.2s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-105.161, total=   9.7s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-2133.210, total=   6.5s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-467.791, total=   6.1s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-1403.728, total=  12.7s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-139.892, total=   5.9s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-101.358, total=  13.5s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-2138.282, total=   8.1s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-467.993, total=   7.7s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-1386.579, total=   7.6s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-142.359, total=   7.3s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-117.303, total=   8.9s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-2140.296, total=   8.9s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-473.597, total=   9.1s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-1382.262, total=   8.2s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-141.447, total=   7.9s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-214.888, total=   9.0s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-2117.802, total=   9.0s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-531.786, total=   9.3s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-1349.840, total=   8.8s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-172.151, total=   6.9s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-292.078, total=   9.6s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-2127.234, total=   9.2s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-516.941, total=   9.5s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-1456.683, total=   7.6s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-123.473, total=   8.5s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-266.835, total=   8.3s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-2114.278, total=   9.9s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-570.595, total=  14.3s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-1292.076, total=   9.5s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-139.886, total=   6.8s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-232.731, total=   7.1s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-2123.187, total=  13.8s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-571.179, total=   8.8s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-1308.848, total=  12.8s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-138.467, total=   5.7s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-101.214, total=   6.1s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-2127.526, total=  11.5s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-459.130, total=   9.5s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-1393.465, total=   6.4s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-139.205, total=   5.7s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-115.329, total=   6.7s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-2136.218, total=   6.3s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-468.892, total=   7.2s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-1377.591, total=   7.2s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-141.069, total=  11.6s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-116.127, total=  13.1s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-2138.980, total=   6.3s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-471.054, total=   6.5s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-1394.347, total=  13.6s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-139.519, total=   7.4s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-110.968, total=   6.8s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-2145.664, total=  10.8s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-471.080, total=   7.2s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-1392.694, total=   7.3s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-130.854, total=  10.3s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-300.631, total=   6.3s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-2153.160, total=   6.3s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-587.902, total=   6.2s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-1400.083, total=  11.4s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-142.881, total=   7.5s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-279.824, total=  10.1s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-2099.081, total=   6.3s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-520.639, total=  12.2s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-1370.394, total=   8.8s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-124.172, total=   6.7s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-203.241, total=  12.1s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-2060.751, total=   6.9s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-440.853, total=   6.9s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-1367.843, total=   7.0s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-218.176, total=  11.8s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-271.229, total=   9.5s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-2081.360, total=   6.8s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-541.872, total=   6.6s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-1380.840, total=  13.3s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-136.173, total=   9.9s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-107.311, total=   8.2s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-2138.044, total=  15.7s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-456.631, total=   8.6s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-1390.672, total=   8.5s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-148.086, total=  16.1s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-119.269, total=   8.6s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-2130.940, total=   8.6s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-467.705, total=  14.7s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-1383.833, total=   9.1s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-145.867, total=  12.5s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-111.831, total=   8.9s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-2142.577, total=  16.6s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-470.059, total=   8.1s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-1389.979, total=  14.6s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-150.195, total=   8.7s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-124.784, total=  14.1s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-2149.962, total=  11.6s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-474.290, total=   9.7s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-1402.450, total=  15.1s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-131.863, total=   8.0s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-299.192, total=   8.5s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-2123.472, total=  13.4s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-533.923, total=   8.9s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-1358.560, total=  14.9s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-132.902, total=   8.7s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-314.109, total=   8.6s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-2227.662, total=  13.6s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-507.648, total=   8.3s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-1360.892, total=  14.8s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-143.356, total=   8.2s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-343.329, total=  13.4s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-2161.547, total=   8.5s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-514.460, total=  10.5s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-1374.108, total=  14.2s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-247.922, total=  11.4s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-609.831, total=   9.3s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-2159.524, total=  16.0s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-505.400, total=   9.3s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-1292.297, total=  13.4s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-144.509, total=  10.2s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-110.691, total=  16.0s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-2149.555, total=   8.8s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-465.962, total=  12.4s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-1384.047, total=   9.6s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-147.395, total=  10.1s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-125.326, total=   9.7s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-2135.969, total=  10.0s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-478.242, total=  16.2s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-1407.898, total=   8.9s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-138.156, total=   9.3s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-121.607, total=  10.3s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-2148.509, total=  10.2s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-470.837, total=  16.6s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-1405.711, total=   9.5s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-150.047, total=   9.1s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-122.419, total=  15.9s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-2139.617, total=   9.9s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-481.925, total=  14.6s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-1393.764, total=   9.8s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-135.272, total=  12.5s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-297.043, total=   8.9s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-2095.837, total=   9.4s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-550.959, total=  14.6s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-1357.554, total=   8.8s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-141.680, total=   9.0s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-410.834, total=  15.1s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-2150.509, total=   8.9s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-527.647, total=   9.7s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-1390.828, total=   9.1s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-201.696, total=  14.9s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-403.423, total=  10.6s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-2298.078, total=  14.2s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-555.685, total=   8.8s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-1401.536, total=  14.7s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-121.814, total=   8.5s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-277.801, total=  12.6s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-2146.285, total=  12.1s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-561.296, total=   9.3s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-1311.147, total=   9.4s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-151.755, total=   5.8s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-104.231, total=   6.4s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-2125.821, total=   3.8s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-461.152, total=   3.3s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-1387.612, total=   6.1s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-156.371, total=   3.3s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-102.161, total=   3.8s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-2123.831, total=   3.6s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-460.101, total=   3.5s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-1383.533, total=   3.9s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-154.576, total=   3.3s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-103.841, total=   7.0s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-2126.848, total=   5.8s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-461.312, total=   3.4s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-1380.593, total=   6.3s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-154.711, total=   3.4s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-102.920, total=   4.1s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-2130.262, total=   3.6s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-458.375, total=   3.6s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-1385.155, total=   6.3s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-148.974, total=   3.5s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-103.793, total=   3.5s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-2135.892, total=   3.6s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-456.682, total=   3.2s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-1385.833, total=   3.8s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-129.684, total=   3.4s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-102.139, total=   3.5s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-2127.508, total=   5.7s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-453.852, total=   6.0s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-1380.364, total=   3.6s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-145.443, total=   3.4s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-133.559, total=   3.8s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-2129.525, total=   3.7s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-457.171, total=   6.4s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-1367.278, total=   3.4s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-167.510, total=   3.5s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-91.251, total=   3.7s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-2124.669, total=   6.2s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-449.317, total=   3.8s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-1376.337, total=   4.4s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-154.638, total=   3.5s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-102.111, total=   3.9s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-2128.755, total=   3.4s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-465.628, total=   3.6s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-1398.569, total=   3.5s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-150.607, total=   5.7s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-105.505, total=   5.2s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-2124.364, total=   3.8s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-460.401, total=   5.6s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-1382.248, total=   3.3s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-153.740, total=   3.5s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-101.749, total=   3.9s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-2122.963, total=   3.6s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-459.611, total=   5.9s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-1381.660, total=   5.3s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-154.097, total=   3.7s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-106.506, total=   3.7s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-2125.519, total=   4.1s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-458.904, total=   3.7s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-1385.667, total=   4.4s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-147.401, total=   3.6s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-94.909, total=   3.9s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-2132.048, total=   6.7s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-452.892, total=   4.5s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-1392.939, total=   3.7s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-141.378, total=   3.6s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-99.657, total=   3.7s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-2128.198, total=   3.8s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-456.487, total=   3.9s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-1376.887, total=   3.9s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-146.236, total=   4.2s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-119.727, total=   3.8s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-2128.563, total=   6.2s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-453.906, total=   7.3s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-1379.627, total=   3.5s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-146.773, total=   4.0s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-99.887, total=   4.0s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-2110.019, total=   4.0s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-463.924, total=   4.7s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-1379.463, total=   4.3s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-152.418, total=   5.8s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-104.186, total=   6.6s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-2133.797, total=   5.9s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-458.861, total=  10.7s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-1390.984, total=   6.0s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-151.321, total=   5.8s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-104.214, total=   7.1s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-2127.687, total=   6.3s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-460.848, total=   5.8s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-1387.399, total=   6.1s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-153.712, total=   5.8s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-107.602, total=  11.5s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-2134.406, total=   6.3s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-457.658, total=   6.6s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-1392.951, total=   5.8s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-150.368, total=   9.9s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-107.622, total=   6.3s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-2130.738, total=   6.2s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-460.675, total=   6.3s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-1389.408, total=   7.0s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-135.031, total=   6.2s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-98.540, total=   6.4s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-2142.492, total=  11.2s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-456.171, total=   5.6s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-1375.459, total=   6.0s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-152.219, total=   5.5s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-97.682, total=   6.1s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-2132.966, total=  10.6s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-458.377, total=   5.8s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-1377.855, total=   6.0s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-136.184, total=   6.0s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-118.036, total=  11.3s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-2133.413, total=   5.9s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-448.754, total=  10.1s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-1392.229, total=   6.9s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-133.805, total=   6.3s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-101.942, total=  11.3s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-2131.511, total=   6.5s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-455.543, total=   6.4s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-1373.241, total=   7.6s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-152.192, total=   5.6s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-103.913, total=  10.9s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-2130.928, total=   6.3s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-466.418, total=   5.9s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-1384.978, total=   6.2s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-154.419, total=  10.5s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-107.345, total=   6.1s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-2131.500, total=   6.4s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-471.276, total=   7.3s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-1389.226, total=   7.2s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-150.932, total=   6.1s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-104.128, total=  11.8s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-2131.178, total=   7.3s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-456.779, total=   6.0s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-1383.656, total=  10.2s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-152.929, total=   6.2s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-106.018, total=   6.5s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-2131.678, total=   6.8s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-459.163, total=   6.7s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-1387.324, total=   6.8s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-153.536, total=  10.4s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-105.021, total=   8.8s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-2135.719, total=   5.8s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-465.518, total=   6.0s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-1385.932, total=   9.2s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-142.666, total=   6.0s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-96.839, total=   6.0s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-2125.940, total=   6.9s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-451.167, total=  10.8s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-1378.161, total=   5.8s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-133.022, total=   5.7s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-121.695, total=  10.9s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-2133.947, total=   6.7s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-456.635, total=   7.4s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-1385.346, total=   6.6s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-168.735, total=   7.3s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-105.743, total=   8.1s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-2132.915, total=  13.4s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-458.059, total=  12.8s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-1368.634, total=  12.6s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-145.484, total=  23.5s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-106.918, total=  28.3s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-2133.916, total=  19.8s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-466.356, total=  19.8s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-1391.211, total=  22.4s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-153.719, total=  20.6s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-106.400, total=  23.0s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-2134.793, total=  20.0s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-458.168, total=  25.3s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-1393.585, total=  21.1s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-151.733, total=  26.9s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-128.485, total=  18.1s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-2134.865, total=  18.5s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-460.163, total=  20.1s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-1384.602, total=  26.9s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-152.273, total=  16.3s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-106.052, total=  18.4s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-2138.491, total=  18.1s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-458.820, total=  18.7s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-1387.904, total=  17.4s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-158.123, total=  22.1s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-99.664, total=  26.8s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-2128.347, total=  22.6s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-455.306, total=  21.5s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-1380.053, total=  26.1s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-160.609, total=  22.8s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-90.001, total=  23.5s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-2125.934, total=  23.5s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-451.828, total=  27.6s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-1394.659, total=  27.7s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-138.599, total=  30.3s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-97.181, total=  27.5s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-2119.651, total=  25.2s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-456.333, total=  27.3s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-1377.942, total=  18.3s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-143.608, total=  24.5s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-99.028, total=  18.0s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-2134.794, total=  17.2s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-455.536, total=  17.8s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-1390.452, total=  18.8s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-153.453, total=  20.9s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-105.165, total=  20.6s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-2134.798, total=  24.3s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-459.911, total=  26.8s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-1392.580, total=  20.1s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-154.985, total=  24.0s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-108.208, total=  28.8s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-2132.671, total=  23.6s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-458.093, total=   7.0s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-1393.575, total=   7.6s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-150.472, total=   6.6s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-101.992, total=   9.5s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-2132.647, total=   9.3s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-455.103, total=   9.4s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-1385.630, total=   9.7s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-155.472, total=  10.1s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-110.248, total=   9.5s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-2133.097, total=   9.7s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-457.045, total=  10.1s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-1388.819, total=   9.4s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-150.434, total=   8.3s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-98.576, total=   9.1s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-2128.890, total=   9.3s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-452.665, total=   9.3s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-1381.792, total=  10.2s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-154.620, total=   9.4s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-107.614, total=   9.7s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-2129.733, total=  10.5s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-456.723, total=   9.6s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-1381.537, total=   9.9s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-144.882, total=   9.8s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-98.724, total=  10.7s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-2129.446, total=  10.2s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-459.849, total=  10.1s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-1381.674, total=  11.2s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-144.415, total=   8.7s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-114.369, total=  12.0s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-2129.976, total=  10.1s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-451.147, total=  10.1s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-1384.546, total=  12.8s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-142.515, total=   4.3s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-98.072, total=   4.9s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-2125.600, total=   2.9s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-457.776, total=   6.6s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-1368.242, total=   2.9s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-141.911, total=   5.8s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-99.392, total=   3.0s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-2126.066, total=   3.3s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-458.501, total=   6.0s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-1377.940, total=   3.0s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-146.888, total=   6.0s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-101.599, total=   3.0s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-2126.917, total=   6.2s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-459.431, total=   3.3s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-1384.763, total=   6.1s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-143.174, total=   2.9s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-104.008, total=   6.1s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-2129.182, total=   2.9s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-458.155, total=   6.8s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-1372.517, total=   2.9s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-158.073, total=   6.1s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-100.510, total=   2.9s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-2115.788, total=   6.6s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-454.116, total=   4.8s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-1388.510, total=   3.0s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-136.328, total=   6.3s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-85.000, total=   3.1s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-2137.295, total=   6.4s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-450.574, total=   3.0s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-1373.507, total=   6.1s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-133.243, total=   2.7s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-115.422, total=   6.1s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-2132.313, total=   4.5s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-453.789, total=   5.3s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-1373.758, total=   6.1s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-126.895, total=   3.9s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-98.730, total=   3.6s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-2122.842, total=   6.8s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-453.474, total=   3.0s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-1374.280, total=   6.1s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-140.775, total=   2.8s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-98.170, total=   6.5s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-2126.809, total=   2.8s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-456.701, total=   6.0s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-1370.926, total=   2.9s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-149.242, total=   6.0s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-100.921, total=   4.4s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-2128.690, total=   2.9s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-467.382, total=   6.0s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-1372.590, total=   8.6s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-144.628, total=   7.6s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-95.218, total=   4.4s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-2128.359, total=   8.6s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-456.103, total=   5.0s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-1379.762, total=   5.7s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-149.206, total=   5.6s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-110.590, total=   3.4s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-2120.337, total=   7.4s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-458.950, total=   4.9s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-1387.623, total=   6.3s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-145.066, total=   2.7s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-88.662, total=   6.1s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-2131.946, total=   3.0s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-452.072, total=   6.3s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-1382.961, total=   2.9s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-158.303, total=   6.4s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-93.658, total=   3.6s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-2125.692, total=   5.6s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-453.227, total=   5.3s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-1364.762, total=   2.9s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-133.829, total=   6.7s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-92.931, total=   4.9s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-2149.897, total=   4.1s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-464.712, total=   5.6s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-1372.974, total=   3.4s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-160.825, total=   5.5s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-84.457, total=   3.4s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-2123.080, total=   8.6s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-452.768, total=   5.1s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-1369.160, total=   6.7s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-140.628, total=   6.8s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-97.602, total=  13.1s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-2136.114, total=   8.3s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-459.434, total=  10.4s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-1382.774, total=   9.7s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-142.264, total=   7.6s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-110.463, total=   9.0s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-2130.454, total=   9.7s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-455.732, total=   7.4s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-1382.405, total=   6.9s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-152.713, total=   9.6s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-98.363, total=   9.4s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-2131.288, total=  12.2s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-454.987, total=   8.1s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-1388.219, total=   8.2s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-144.854, total=  11.3s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-108.668, total=   7.5s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-2133.371, total=  10.0s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-456.646, total=  12.1s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-1387.115, total=  10.5s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-126.763, total=   6.5s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-97.816, total=   9.5s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-2132.359, total=   8.9s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-458.525, total=  11.4s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-1377.528, total=   7.4s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-147.199, total=  13.6s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-102.674, total=   9.9s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-2137.788, total=  15.0s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-458.324, total=   7.3s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-1392.760, total=  13.1s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-120.489, total=   8.1s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-87.108, total=  13.3s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-2121.024, total=   9.4s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-455.388, total=   8.9s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-1425.602, total=  14.0s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-147.598, total=   7.3s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-92.172, total=  13.4s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-2128.871, total=   7.0s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-456.790, total=  11.8s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-1378.555, total=   8.9s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-140.235, total=   9.1s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-103.411, total=   5.2s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-2132.982, total=   9.3s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-461.699, total=   8.7s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-1389.084, total=   4.8s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-148.721, total=   9.1s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-108.495, total=   9.2s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-2136.322, total=   4.9s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-456.447, total=   9.3s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-1385.987, total=   9.4s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-146.055, total=   5.8s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-98.744, total=   8.8s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-2136.542, total=   8.4s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-454.204, total=   8.8s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-1387.509, total=   8.9s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-147.930, total=   9.7s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-99.980, total=   8.5s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-2132.334, total=   6.5s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-460.590, total=   9.9s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-1384.275, total=   8.6s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-143.650, total=   7.6s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-101.770, total=   7.5s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-2130.128, total=   8.7s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-456.629, total=   9.3s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-1370.635, total=   4.8s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-187.442, total=  10.1s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-99.926, total=   9.9s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-2127.924, total=  15.2s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-462.463, total=   7.9s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-1387.276, total=  10.7s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-144.522, total=   7.3s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-82.361, total=   6.9s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-2123.137, total=  10.3s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-455.611, total=  10.8s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-1394.277, total=  12.1s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-165.809, total=   5.9s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-94.245, total=  13.0s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-2131.442, total=   8.0s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-457.724, total=   8.2s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-1368.098, total=   8.9s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-149.203, total=  12.0s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-117.006, total=  10.3s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-2135.360, total=  12.2s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-461.914, total=   9.4s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-1382.921, total=  15.7s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-152.346, total=   9.9s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-106.426, total=  11.0s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-2134.973, total=  12.0s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-465.139, total=  11.5s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-1386.132, total=  14.6s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-138.885, total=  14.6s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-100.429, total=  10.7s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-2133.126, total=  14.9s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-457.554, total=  13.0s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-1383.192, total=  15.8s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-152.509, total=  13.6s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-100.161, total=  11.9s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-2134.540, total=  13.1s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-459.301, total=  14.6s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-1395.644, total=  11.6s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-148.726, total=  13.1s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-107.696, total=  11.6s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-2131.900, total=  11.9s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-452.993, total=  13.4s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-1382.351, total=  12.8s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-138.651, total=   9.5s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-101.728, total=  11.9s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-2122.809, total=  12.6s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-457.597, total=  10.0s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-1384.148, total=  12.7s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-141.895, total=  13.3s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-99.536, total=  11.6s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-2127.579, total=  11.9s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-456.721, total=  11.8s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-1378.860, total=  13.3s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-155.407, total=  12.4s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-107.816, total=  11.4s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-2125.578, total=  12.0s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-450.238, total=  13.3s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-1361.018, total=  13.7s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-147.988, total=  11.6s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-96.825, total=  12.9s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-2132.040, total=  10.6s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-456.911, total=  14.3s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-1386.069, total=  13.4s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-144.640, total=   9.8s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-105.697, total=  11.0s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-2131.538, total=  10.6s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-457.065, total=  10.5s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-1386.119, total=  13.5s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-145.303, total=  10.6s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-103.754, total=  13.6s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-2136.321, total=  12.1s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-455.613, total=  14.3s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-1380.940, total=  15.1s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-140.729, total=  12.4s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-103.677, total=  11.6s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-2131.642, total=  11.8s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-460.117, total=  14.9s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-1378.745, total=  11.0s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-127.507, total=  10.8s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-98.924, total=   9.9s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-2127.084, total=  11.5s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-453.270, total=  11.2s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-1374.845, total=  13.4s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-142.875, total=   8.2s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-102.252, total=  10.1s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-2125.570, total=  12.5s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-446.521, total=  12.8s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-1374.649, total=  13.3s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-141.103, total=  14.2s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-90.804, total=  14.9s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-2124.959, total=  12.0s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-450.404, total=  10.3s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-1366.004, total=  11.0s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-138.230, total=  13.7s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-103.359, total=  16.2s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-2125.912, total=  10.3s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-453.637, total=  13.8s\n",
      "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
      "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-1363.927, total=  11.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 960 out of 960 | elapsed: 138.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------- Done -----------------------------\n"
     ]
    }
   ],
   "source": [
    "# create general model which is use to find better parameter :\n",
    "def create_model(learning_rate,dropout_rate,activation_function,init,neuron1,neuron2):\n",
    "    m = Sequential()\n",
    "    m.add(Dense(neuron1,input_dim = 9,kernel_initializer = init,activation = activation_function))\n",
    "    m.add(Dropout(dropout_rate))\n",
    "    m.add(Dense(neuron2,input_dim = neuron1,kernel_initializer = init,activation = activation_function))\n",
    "    m.add(Dropout(dropout_rate))\n",
    "    m.add(Dense(1,kernel_initializer='normal'))\n",
    "    \n",
    "    adam = Adam(lr = learning_rate)\n",
    "    m.compile(loss = 'mean_squared_error',optimizer = adam)\n",
    "    return m\n",
    "\n",
    "# Create the model\n",
    "\n",
    "model = KerasRegressor(build_fn = create_model,verbose = 0)\n",
    "\n",
    "# Define the grid search parameters\n",
    "\n",
    "batch_size = [10]\n",
    "epochs = [100,200,300]\n",
    "learning_rate = [0.001,0.01]\n",
    "dropout_rate = [0.0,0.1]\n",
    "activation_function = ['relu','linear']\n",
    "init = ['uniform','normal']\n",
    "neuron1 = [8,14]\n",
    "neuron2 = [6,9]\n",
    "\n",
    "# Make a dictionary of the grid search parameters\n",
    "\n",
    "param_grids = dict(batch_size = batch_size,epochs = epochs,learning_rate = learning_rate,dropout_rate = dropout_rate,\n",
    "                   activation_function = activation_function,init = init,neuron1 = neuron1,neuron2 = neuron2)\n",
    "\n",
    "# Build and fit the GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(np.array(x_scaled),np.array(y))\n",
    "\n",
    "print(\"------------------------------- Done -----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=500, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=500, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8, score=-1315.049, total=  10.0s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=500, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    9.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=500, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8, score=-3789.486, total=  11.2s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=500, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   21.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=500, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8, score=-2837.569, total=  13.2s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=500, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   34.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=500, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8, score=-678.428, total=  12.9s\n",
      "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=500, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   47.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=500, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8, score=-2155.582, total=  13.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------- Done -----------------------------\n"
     ]
    }
   ],
   "source": [
    "# after applying general model get the best hyperparameters and make another model model_1 :\n",
    "def create_model(learning_rate,dropout_rate,activation_function,init,neuron1,neuron2):\n",
    "    m = Sequential()\n",
    "    m.add(Dense(neuron1,input_dim = 9,kernel_initializer = init,activation = activation_function))\n",
    "    m.add(Dropout(dropout_rate))\n",
    "    m.add(Dense(neuron2,input_dim = neuron1,kernel_initializer = init,activation = activation_function))\n",
    "    m.add(Dropout(dropout_rate))\n",
    "    m.add(Dense(1,kernel_initializer='normal'))\n",
    "    \n",
    "    adam = Adam(lr = learning_rate)\n",
    "    m.compile(loss = 'mean_squared_error',optimizer = adam)\n",
    "    return m\n",
    "\n",
    "# Create the model\n",
    "\n",
    "model_1 = KerasRegressor(build_fn = create_model,verbose = 0)\n",
    "\n",
    "# Define the grid search parameters\n",
    "\n",
    "batch_size = [10]\n",
    "epochs = [500]\n",
    "learning_rate = [0.01]\n",
    "dropout_rate = [0.0]\n",
    "activation_function = ['relu']\n",
    "init = ['uniform']\n",
    "neuron1 = [8]\n",
    "neuron2 = [8]\n",
    "\n",
    "# Make a dictionary of the grid search parameters\n",
    "\n",
    "param_grids = dict(batch_size = batch_size,epochs = epochs,learning_rate = learning_rate,dropout_rate = dropout_rate,\n",
    "                   activation_function = activation_function,init = init,neuron1 = neuron1,neuron2 = neuron2)\n",
    "\n",
    "# Build and fit the GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(estimator = model_1,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(np.array(x_scaled),np.array(y))\n",
    "\n",
    "print(\"------------------------------- Done -----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------ Results-----------------------------------------------\n",
      "Best : -2155.2226440429686, using {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 500, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 8}\n",
      "-2155.2226440429686,1097.5635431430462 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 500, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 8}\n",
      "********************* Done ************************\n"
     ]
    }
   ],
   "source": [
    "# Summarize the results for new model :\n",
    "print(\"------------------ Results-----------------------------------------------\")\n",
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print('{},{} with: {}'.format(mean, stdev, param))\n",
    "print(\"********************* Done ************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.callbacks.History object at 0x000001E61E581D90>\n",
      "********************************done***********************************\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# apply hyperparameters to get better model :\n",
    "import numpy as np\n",
    "# Create the model :\n",
    "kfold = KFold(n_splits=10)\n",
    "def create_model():\n",
    "    m = Sequential()\n",
    "    m.add(Dense(8, input_dim=9, kernel_initializer = 'normal', activation='relu'))\n",
    "    m.add(Dense(6, kernel_initializer='normal', activation='relu'))\n",
    "    # m.add(Dense(3, kernel_initializer='normal', activation='linear'))\n",
    "    m.add(Dense(1, kernel_initializer='normal'))\n",
    "    \n",
    "    adam=Adam(lr=0.01)\n",
    "#     optimizer = Adadelta()\n",
    "# compile model :\n",
    "    m.compile(loss='mean_squared_error', optimizer=adam, metrics=['mse'])\n",
    "    return m\n",
    "\n",
    "final_model = create_model()\n",
    "history = final_model.fit(np.array(x_scaled), np.array(y), epochs=500, batch_size=10, verbose=0)\n",
    "print(history)\n",
    "print(\"********************************done***********************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186.65199279785156\n"
     ]
    }
   ],
   "source": [
    "# now apply final model on testing and training data :\n",
    "mse_value, mae_value = final_model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print(mse_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict test data :\n",
    "final_y_test_pred = final_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.5265782724160957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1e6172e3f70>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# testing score :\n",
    "print(r2_score(final_y_test_pred, y_test))    \n",
    "plt.scatter(final_y_test_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data prediction :\n",
    "final_y_train_pred = final_model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.49958490017377977\n"
     ]
    }
   ],
   "source": [
    "# accuracy score for training data using final_model :\n",
    "print(r2_score(final_y_train_pred, y_train))    # 67.64 % training accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visulize loss w.r.t epochs :\n",
    "fig, (ax1, ax2) = plt.subplots(2,1, figsize=(12,6))\n",
    "ax2.plot(history.history['mse'], color='orange')\n",
    "ax2.legend(loc='upper right')\n",
    "ax1.plot(history.history['loss'], label='Loss')\n",
    "ax1.legend(loc=\"upper right\")\n",
    "ax1.set_title(\"Model-Accuracy w.r.t Epochs\", loc='center')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"mean-squared-error\")\n",
    "ax1.set_xlabel(\"Epoch\")\n",
    "ax1.set_ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefor, we can conclude that model made of extracted feature doesn't give good prediction , Thats why model made of using whole features is good model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
